{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thaarres/quantumUniverse_pynqZ2/blob/master/part1_ADmodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXxp5EdiwEk3"
      },
      "source": [
        "# How-to: Anomaly detection in nanoseconds on an FPGA\n",
        "\n",
        "<img src=\"https://github.com/thaarres/quantumUniverse_pynqZ2/blob/master/images/front.png?raw=1\" alt=\"The ADC2021 Challenge\" width=\"300\" img align=\"right\"/>\n",
        "\n",
        "In this notebook we will demonstrate how to design a tiny autoencoder (AE) that we will use for anomaly detection in particle physics. More specifically, we will demonstrate how we can use autoencoders to select potentially New Physics enhanced proton collision events in a more unbiased way than with the usual Level-1 trigger algorithms!\n",
        "\n",
        "Some of the key tools we will use in order to make our AE fast and small enought to fit within the strict latency and resource budget of a L1 trigger algorithm are:\n",
        "- Quantization\n",
        "- Pruning\n",
        "- Highly parallel deployment using hls4ml!\n",
        "\n",
        "We will train the autoencoder to learn to compress and decompress data, assuming that for highly anomalous events, the AE will fail.\n",
        "\n",
        "## Dataset\n",
        "\n",
        "As a dataset, we will use the [ADC2021 dataset](https://mpp-hep.github.io/ADC2021/). It is represented as an array of missing transverse energy (MET), up to 4 e/ùõæ, up to 4 muons and 10 jets each described by pT, Œ∑, œÜ and particle ID to mimic a L1 data format. The particles are ordered by pT. If fewer objects are present, the event is zero padded in such a way that the 1st, 5th, and 9th positions correspond to the highest-$p_T$ electron, muon, and jet, respectively. The last index (with cardinality 4) runs over the three features describing each physics object and a particle type index, which is equal to 1, 2, 3 and 4 for MET, electron, muon and jet, respectively.\n",
        "\n",
        "You can train using the provided 4 million background-like events\n",
        "simulated with Delphes, where the events are pre-filtered to have at least one lepton\n",
        "<img src=\"https://github.com/thaarres/quantumUniverse_pynqZ2/blob/master/images/datagrid.png?raw=1\" alt=\"Background data\" width=\"300\" img align=\"right\"/>\n",
        "- Inclusive W production, with W ‚Üí lùúà (59.2%)\n",
        "- Inclusive Z production, with Z ‚Üí ll (6.7%)\n",
        "- tt production (0.3%)\n",
        "- QCD multijet production (33.8%)\n",
        "\n",
        "You can then evaluate the AE performance on several different New Physics simulated samples:\n",
        "- Neutral scalar boson A, 50 GeV ‚Üí 4 l\n",
        "- Leptoquark, 80 GeV ‚Üí b œÑ\n",
        "- Scalar boson, 60 GeV ‚Üí œÑ œÑ\n",
        "- Charged scalar boson, 60 GeV ‚Üí œÑ ùúà\n",
        "- Black Box (mix of background and an unknown signal!!)\n",
        "\n",
        "We'll train using all the background data and test using the A (50 GeV) ‚Üí 4 l sample. Let's fetch them! The background data can be downloaded [here](https://zenodo.org/record/5046389#.YaeRWL3MLze) and the signal data [here](https://zenodo.org/record/5046446#.YaeSa73MLzd). I have already downloaded it and moved it to folder called `data/`, you can do it by executing the following cell:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pHpj7cn6wEk5",
        "outputId": "d8e1ab19-ac04-4129-e556-3d2388d6d0e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5443307"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "if not os.path.exists('data/'):\n",
        "    os.mkdir('data/')\n",
        "\n",
        "url = \"https://zenodo.org/record/5046389/files/background_for_training.h5?download=1\"\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "open('data/background_for_training.h5', 'wb').write(r.content)\n",
        "\n",
        "url = \"https://zenodo.org/record/5046446/files/Ato4l_lepFilter_13TeV.h5?download=1\"\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "open('data/Ato4l_lepFilter_13TeV.h5', 'wb').write(r.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYrg2CqFwEk6"
      },
      "source": [
        "\n",
        "Let's prepare the data!\n",
        "Having very different numerical ranges for the input features, as in this case where $p_T$, $\\eta$ and $\\phi$ have a very diffent mean, makes it difficult for the network to converge. We will therefore standardize the $p_T$.  Also, when there is no lepton present in the event, the values will be zero padded. That means there is an unnatural number of zero entries in the $p_T$. For a real use case, the loss should be rewritten as to not take zero entries into account. Ideally we would also deal with the periodicity of phi etc. Details on the best procedure for preprccesing can be found in [this paper](https://arxiv.org/abs/2108.03986). In the interest of time, we'll only do the $p_T$ scaling.\n",
        "\n",
        "In addition, we also flatten the 2D grid into a 1D array to prepare feeding it into a dense network, and split the training data into train/validation/test sets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CAQY2-qywEk7",
        "outputId": "6df701db-9c27-4ed5-d78a-554e5bf300c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape = (N samples, N particles, N features) =  (4000000, 19, 3)\n",
            "Training data shape =  (2560000, 57)\n"
          ]
        }
      ],
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "nbkg_events = None #Depending how much time you have, you can use all of this data or only a fraction\n",
        "# read BACKGROUND data and shuffle it in preparation for training. This takes a while so I've done it in advance!\n",
        "with h5py.File('data/background_for_training.h5', 'r') as file:\n",
        "    full_data = file['Particles'][:,:,:-1] # The last column is the particle ID and we'll skip that for now\n",
        "    print(\"Data shape = (N samples, N particles, N features) = \",full_data.shape)\n",
        "    np.random.shuffle(full_data)\n",
        "    if nbkg_events: full_data = full_data[:nbkg_events,:,:]\n",
        "    pt_scaler = StandardScaler()\n",
        "    full_data[:,:,0] = pt_scaler.fit_transform(full_data[:,:,0])\n",
        "\n",
        "\n",
        "# define training, test and validation datasets\n",
        "X_train, X_test = train_test_split(full_data, test_size=0.2, shuffle=True)\n",
        "X_train, X_val = train_test_split(X_train, test_size=0.2)\n",
        "\n",
        "del full_data\n",
        "\n",
        "input_shape= X_train.shape[1]*X_train.shape[2]\n",
        "# flatten the data for model input\n",
        "X_train = X_train.reshape(X_train.shape[0], input_shape)\n",
        "X_test = X_test.reshape(X_test.shape[0], input_shape)\n",
        "X_val = X_val.reshape(X_val.shape[0], input_shape)\n",
        "print(\"Training data shape = \",X_train.shape)\n",
        "with h5py.File('bkg_dataset.h5', 'w') as h5f:\n",
        "    h5f.create_dataset('X_train', data = X_train)\n",
        "    h5f.create_dataset('X_test', data = X_test)\n",
        "    h5f.create_dataset('X_val', data = X_val)\n",
        "\n",
        "with h5py.File('data/Ato4l_lepFilter_13TeV.h5', 'r') as file:\n",
        "    signal_data = file['Particles'][:,:,:-1]\n",
        "    signal_data[:,:,0] = pt_scaler.transform(signal_data[:,:,0])\n",
        "    signal_data = signal_data.reshape(signal_data.shape[0],input_shape)\n",
        "with h5py.File('Ato4l_dataset.h5', 'w') as h5f2:\n",
        "    h5f2.create_dataset('Data', data = signal_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbb9wX52wEk7"
      },
      "source": [
        "You  now have two new files in your reposity, `bkg_dataset.h5` and `Ato4l_dataset.h5` which contains your train/test/val data to train the autoencoder, as well as a test data to check your performance on a New Physics signal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXw_69O-wEk7"
      },
      "source": [
        "Let's inspect the training data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JrCYeQyDwEk7"
      },
      "outputs": [],
      "source": [
        "with h5py.File('bkg_dataset.h5', 'r') as file:\n",
        "    X_train = np.array(file['X_train'])\n",
        "    X_test = np.array(file['X_test'])\n",
        "    X_val = np.array(file['X_val'])\n",
        "\n",
        "with h5py.File('Ato4l_dataset.h5', 'r') as file:\n",
        "    signal_test_data = np.array(file['Data'])\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xutXs2OqwEk7",
        "outputId": "7d779755-8976-496e-ba89-49e2d6249166",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 814
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Training (#samples,#features): (2560000, 57)\n",
            " Testing  (#samples,#features): (55969, 57)\n",
            "Example data (1,57): [-1.08718776e+00  0.00000000e+00 -2.66409016e+00  4.69884523e-01\n",
            "  2.31486845e+00  6.83920026e-01 -3.58555796e-02  0.00000000e+00\n",
            "  0.00000000e+00 -1.06082268e-02  0.00000000e+00  0.00000000e+00\n",
            " -2.57502857e-03  0.00000000e+00  0.00000000e+00  4.34388275e-02\n",
            "  1.17693150e+00  1.64127874e+00 -2.98743154e-02  0.00000000e+00\n",
            "  0.00000000e+00 -8.17884995e-03  0.00000000e+00  0.00000000e+00\n",
            " -1.97147069e-03  0.00000000e+00  0.00000000e+00  9.68097462e-01\n",
            "  2.31548548e+00 -2.58200836e+00  2.21721723e+00  2.31486845e+00\n",
            "  6.83920026e-01 -1.48533390e-01  0.00000000e+00  0.00000000e+00\n",
            " -8.71758427e-02  0.00000000e+00  0.00000000e+00 -5.73052558e-02\n",
            "  0.00000000e+00  0.00000000e+00 -3.98315065e-02  0.00000000e+00\n",
            "  0.00000000e+00 -2.73385808e-02  0.00000000e+00  0.00000000e+00\n",
            " -1.81327909e-02  0.00000000e+00  0.00000000e+00 -1.16929442e-02\n",
            "  0.00000000e+00  0.00000000e+00 -7.32868055e-03  0.00000000e+00\n",
            "  0.00000000e+00]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAr4AAAH2CAYAAACWZI/pAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAdPJJREFUeJzt3XlcVOX+B/DPzLCpLMq+qZiaiiaYCFlaLhSiYmql9+otXLIyMP1RmXa7apuaqVE26dVSvG2aLVZapqlppamoZKWZFu6AO5uKMvP8/rA5MswMDDAzZ2bO5/168ao5c5bnMPDl63Oe5/uohBACRERERERuTi13A4iIiIiIHIGJLxEREREpAhNfIiIiIlIEJr5EREREpAhMfImIiIhIEZj4EhEREZEiMPElIiIiIkVg4ktEREREisDEl4iIiIgUgYkvkQxmzJgBlUoldzPs7rvvvoNKpcJ3331nt2vk5ORApVLhyJEj0rZevXqhV69edrtmVSqVCjNmzJBeGz7bs2fPOuT6MTExGDVqlEOuVVejRo1CTEyMzc5n+Kxzc3Nr3TcmJgYDBw602bWdla2/xw3lzD+PRAATXyKbsfRHubi4GImJifDx8cG6detkap19vfXWW8jJyZG7GQ2ybds2zJgxAxcvXpS7KSacuW1ERK7EQ+4GELmzkpIS3HPPPdi3bx8+++wz9OvXDwDw3HPPYcqUKTK3znbeeustBAcHm/T03Hnnnbh8+TK8vLwc2p7169fX+Zht27bh+eefx6hRo9C0aVOrj7t8+TI8POwbSmtq28GDB6FWO2cfxpIlS6DX6+Vuhlvj95iobpj4EtlJaWkpUlJSkJeXh08//RSpqanSex4eHnZPlpyBWq2Gj4+Pw69r70Rbr9fj6tWr8PHxkeX+qvL29pb1+jXx9PSUuwluj99jorpxzm4CIhdXVlaGfv36Yc+ePfjkk08wYMAAo/fNjfFVqVTIzMzE6tWr0alTJ3h7e6Njx45mh0ecPHkSY8aMQVhYmLTf0qVLjfYxjK/96KOP8PzzzyMqKgp+fn64//77UVxcjIqKCkyaNAmhoaHw9fXF6NGjUVFRYXSOZcuWoU+fPggNDYW3tzdiY2OxcOFCo31iYmLw22+/YcuWLVCpVFCpVNL4WktjfHfs2IH+/fujWbNmaNKkCTp37ozXX3+91u/rb7/9hj59+qBRo0aIjo7GSy+9ZLa3y9wY3wULFqBjx45o3LgxmjVrhoSEBHzwwQcArn8eTz/9NACgVatW0n0Yxg0bPpv3338fHTt2hLe3t/S5VB/ja3D27FkMGzYM/v7+CAoKwsSJE3HlyhXp/SNHjkClUpkdIlL1nLW1zdyYyr/++gsPPPAAAgMD0bhxY9x2221Yu3at0T5Vfz5efvllREdHw8fHB3379sXhw4eN9j106BDuu+8+hIeHw8fHB9HR0fjHP/6B4uJik7ZXVX38qeGe586di8WLF6N169bw9vZGt27dsGvXrhrPVdWlS5fw6KOPIigoCP7+/njooYdw4cKFWo9bvnw5PDw8pO8nAJw7dw4PPvgg/P390bRpU6Snp+Pnn3+2+NkY5ObmQqVSYfny5SbvffPNN1CpVFizZg2A6/8InjRpEmJiYuDt7Y3Q0FDcfffd2LNnT43tteY4c2N8rb2nUaNGwdfXFydPnsTgwYPh6+uLkJAQPPXUU9DpdEbnnDt3Lm6//XYEBQWhUaNG6Nq1Kz7++OMa20/kjNy/y4nIwcrLy5Gamopdu3bh448/rtMEmx9++AGffvopHn/8cfj5+eGNN97Afffdh2PHjiEoKAgAUFRUhNtuu01KxkJCQvD1119j7NixKCkpwaRJk4zOOWvWLDRq1AhTpkzB4cOHsWDBAnh6ekKtVuPChQuYMWMGfvrpJ+Tk5KBVq1aYNm2adOzChQvRsWNHDBo0CB4eHvjyyy/x+OOPQ6/XIyMjAwCQnZ2NCRMmwNfXF//+978BAGFhYRbvccOGDRg4cCAiIiIwceJEhIeH48CBA1izZg0mTpxo8bjCwkL07t0blZWVmDJlCpo0aYLFixejUaNGtX5flyxZgieeeAL333+/lIDu27cPO3bswIgRIzB06FD88ccf+PDDD/Haa68hODgYABASEiKdY9OmTfjoo4+QmZmJ4ODgWicUDRs2DDExMZg1axZ++uknvPHGG7hw4QL+97//1dreqqxpW1VFRUW4/fbbcenSJTzxxBMICgrC8uXLMWjQIHz88ccYMmSI0f6zZ8+GWq3GU089heLiYsyZMwcjR47Ejh07AABXr15FSkoKKioqMGHCBISHh+PkyZNYs2YNLl68iICAgDrdDwB88MEHKC0txaOPPgqVSoU5c+Zg6NCh+Ouvv6zqwczMzETTpk0xY8YMHDx4EAsXLsTRo0elZN6cxYsX47HHHsOzzz6Ll156CcD1nvu0tDTs3LkT48ePR/v27fH5558jPT291jYkJCTgpptuwkcffWSy/8qVK9GsWTOkpKQAAB577DF8/PHHyMzMRGxsLM6dO4cffvgBBw4cwK233mrxGvU5rq73pNPpkJKSgqSkJMydOxfffvst5s2bh9atW2P8+PHSfq+//joGDRqEkSNH4urVq1ixYgUeeOABrFmzxuQf9kROTRCRTSxbtkwAEC1bthSenp5i9erVFvedPn26qP7rB0B4eXmJw4cPS9t+/vlnAUAsWLBA2jZ27FgREREhzp49a3T8P/7xDxEQECAuXbokhBBi8+bNAoDo1KmTuHr1qrTfP//5T6FSqURqaqrR8d27dxctW7Y02mY4V1UpKSnipptuMtrWsWNHcdddd5nsa2jD5s2bhRBCVFZWilatWomWLVuKCxcuGO2r1+tNjq9q0qRJAoDYsWOHtO306dMiICBAABD5+fnS9rvuusuoPffee6/o2LFjjed/9dVXTc5jAECo1Wrx22+/mX1v+vTp0mvDZzto0CCj/R5//HEBQPz8889CCCHy8/MFALFs2bJaz1lT21q2bCnS09Ol14bv0/fffy9tKy0tFa1atRIxMTFCp9MJIW58Nh06dBAVFRXSvq+//roAIH755RchhBB79+4VAMSqVatMrl2b9PR0o58pwz0HBQWJ8+fPS9s///xzAUB8+eWXNZ7P8DvWtWtXo5/pOXPmCADi888/l7a1bNlSDBgwQLonlUolXnzxRaPzffLJJwKAyM7OlrbpdDrRp08fi59NVVOnThWenp5G91JRUSGaNm0qxowZI20LCAgQGRkZNZ7LHGuOq/49rss9paenCwDihRdeMDpnly5dRNeuXY22VY8FV69eFZ06dRJ9+vQx2l7955HI2XCoA5GNFRUVwcfHB82bN6/zscnJyWjdurX0unPnzvD398dff/0FABBC4JNPPkFaWhqEEDh79qz0lZKSguLiYpPHpw899JBRL1pSUhKEEBgzZozRfklJSTh+/DgqKyulbVV7U4uLi3H27Fncdddd+Ouvv2p9zG3O3r17kZ+fj0mTJplM0qqtvNtXX32F2267DYmJidK2kJAQjBw5stbrNm3aFCdOnKjT4/Tq7rrrLsTGxlq9v6FH3GDChAkArt+HPX311VdITExEjx49pG2+vr545JFHcOTIEezfv99o/9GjRxuNie7ZsycASD9zhh7db775BpcuXbJJG4cPH45mzZpZvGZtHnnkEaOf6fHjx8PDw8Ps93bOnDmYOHEiXnnlFTz33HNG761btw6enp4YN26ctE2tVpt8djXdx7Vr1/Dpp59K29avX4+LFy9i+PDh0ramTZtix44dOHXqlFXnbchx9bmnxx57zOh1z549TT6LqrHgwoULKC4uRs+ePWsdrkHkbJj4EtnYf//7X3h5eaFfv344ePBgnY5t0aKFybZmzZpJ4xfPnDmDixcvYvHixQgJCTH6Gj16NADg9OnTNZ7TkMhUT8wDAgKg1+uNEtoff/wRycnJaNKkCZo2bYqQkBA8++yzAFCvxPfPP/8EAHTq1KnOxx49ehRt27Y12d6uXbtaj33mmWfg6+uLxMREtG3bFhkZGfjxxx/rdP1WrVrVaf/qbW3dujXUarVRvWF7OHr0qNnvSYcOHaT3q6r+82FISA0/c61atUJWVhbefvttBAcHIyUlBVqttl6fv7XXrE31762vry8iIiJMvrdbtmzBM888g2eeecZoXK/B0aNHERERgcaNGxttb9OmjVXtiIuLQ/v27bFy5Upp28qVKxEcHIw+ffpI2+bMmYNff/0VzZs3R2JiImbMmGFVkl+f4+p6Tz4+PibDZqrGHIM1a9bgtttug4+PDwIDAxESEoKFCxc26OeASA5MfIlsLDY2Fl999RUuX76Mu+++G8ePH7f6WI1GY3a7EAIApIlc//rXv7BhwwazX3fccYdV56ztWn/++Sf69u2Ls2fPYv78+Vi7di02bNiA//u//zNqiyvo0KEDDh48iBUrVqBHjx745JNP0KNHD0yfPt3qc1gzlrgm5iYzmlN9UpG91fZzAADz5s3Dvn378Oyzz+Ly5ct44okn0LFjR5w4ccJu17SFjh07ol27dnj33XeRn59v03MbDB8+HJs3b8bZs2dRUVGBL774Avfdd59R1ZZhw4bhr7/+woIFCxAZGYlXX30VHTt2xNdff13juet7XF1Y+iyq+v777zFo0CD4+PjgrbfewldffYUNGzZgxIgRNv/MiOyNiS+RHSQmJmL16tU4ffo07r77bpw5c8Ym5w0JCYGfnx90Oh2Sk5PNfoWGhtrkWl9++aX0h/zRRx9F//79kZycbDYBtHYVOsMwjl9//bXO7WnZsiUOHTpkst3aXvUmTZpg+PDhWLZsGY4dO4YBAwbg5Zdfliot2HolveptPXz4MPR6vTQpztDLWX1Riuo9snVtW8uWLc1+T37//Xfp/fq45ZZb8Nxzz2Hr1q34/vvvcfLkSSxatKhe52qo6t/bsrIyFBQUmEw4DA4OxrfffgtPT0/07dvXZMhAy5YtUVBQYDKEo3pVi5oMHz4clZWV+OSTT/D111+jpKQE//jHP0z2i4iIwOOPP47Vq1cjPz8fQUFBePnll2s9f12Ps8U9VffJJ5/Ax8cH33zzDcaMGYPU1FQkJyfX+3xEcmLiS2Qnffv2xYcffojDhw+jX79+KCkpafA5NRoN7rvvPnzyySdmk0dbJdiGawHGvXDFxcVYtmyZyb5NmjSxalWxW2+9Fa1atUJ2drbJ/rX1HPXv3x8//fQTdu7cKW07c+YM3n///Vqve+7cOaPXXl5eiI2NhRAC165dk+4BME1E60ur1Rq9XrBgAQBI9Zz9/f0RHByMrVu3Gu331ltvmZyrLm3r378/du7cie3bt0vbysvLsXjxYsTExNRpnDJwfRGWquO+getJsFqtNil/5yiLFy+WPjfgevWRyspKo1rZBtHR0fj222+lJzBVfxZSUlJw7do1LFmyRNqm1+tNPruadOjQAbfccgtWrlyJlStXIiIiAnfeeaf0vk6nMxkOEBoaisjIyBq/f/U9zhb3VJ1Go4FKpTJ6GnHkyBGsXr263uckkgvLmRHZ0ZAhQ7BkyRKMGTMGgwYNwrp16xq84MHs2bOxefNmJCUlYdy4cYiNjcX58+exZ88efPvttzh//rxN2n7PPffAy8sLaWlpePTRR1FWVoYlS5YgNDQUBQUFRvt27doVCxcuxEsvvYQ2bdogNDTUaIyjgVqtxsKFC5GWlob4+HiMHj0aERER+P333/Hbb7/hm2++sdieyZMn491330W/fv0wceJEqZxZy5YtsW/fvlrvJTw8HHfccQfCwsJw4MABvPnmmxgwYAD8/PykewCAf//73/jHP/4BT09PpKWlSUlnXeXn52PQoEHo168ftm/fjvfeew8jRoxAXFyctM/DDz+M2bNn4+GHH0ZCQgK2bt2KP/74w+RcdWnblClT8OGHHyI1NRVPPPEEAgMDsXz5cuTn5+OTTz6p8ypvmzZtQmZmJh544AHcfPPNqKysxLvvviv9I0wOV69eRd++fTFs2DAcPHgQb731Fnr06IFBgwaZ3b9NmzZYv349evXqhZSUFGzatAn+/v4YPHgwEhMT8eSTT+Lw4cNo3749vvjiC+l3yNqe9uHDh2PatGnw8fHB2LFjjb7HpaWliI6Oxv3334+4uDj4+vri22+/xa5duzBv3jyL56zvcba6p6oGDBiA+fPno1+/fhgxYgROnz4NrVaLNm3a1Pq7R+R0ZKomQeR2DKWWdu3aZfLe3LlzBQAxcOBAce3aNYvlzMyVLjJXHqioqEhkZGSI5s2bC09PTxEeHi769u0rFi9eLO1jKFdVvQyVpXYa2nTmzBlp2xdffCE6d+4sfHx8RExMjHjllVfE0qVLTUprFRYWigEDBgg/Pz8BQColVr2cmcEPP/wg7r77buHn5yeaNGkiOnfubFSyzZJ9+/aJu+66S/j4+IioqCjx4osvinfeeafWcmb//e9/xZ133imCgoKEt7e3aN26tXj66adFcXGx0flffPFFERUVJdRqtdE5LX02hvfMlTPbv3+/uP/++4Wfn59o1qyZyMzMFJcvXzY69tKlS2Ls2LEiICBA+Pn5iWHDhonTp0+bnLOmtpn7+fjzzz/F/fffL5o2bSp8fHxEYmKiWLNmjdE+ln4+qpdZ++uvv8SYMWNE69athY+PjwgMDBS9e/cW3377rdnvR1WWypm9+uqrtX4fzTH87G7ZskU88sgjolmzZsLX11eMHDlSnDt3zmjfquXMDHbs2CH8/PzEnXfeKZXnOnPmjBgxYoTw8/MTAQEBYtSoUeLHH38UAMSKFStqvUchhDh06JAAIACIH374wei9iooK8fTTT4u4uDjp5z0uLk689dZbNZ7T2uOqf4/rck/p6emiSZMmJtc2F5/eeecd0bZtW+Ht7S3at28vli1bZnY/ljMjZ6cSgiPTiYiIDFavXo0hQ4bghx9+MJks6qrc8Z6I6oOJLxERKdbly5eNJmzqdDrcc889yM3NRWFhYYOrecjBHe+JyFY4xpeIiBRrwoQJuHz5Mrp3746Kigp8+umn2LZtG2bOnOmyCaI73hORrbDHl4iIFOuDDz7AvHnzcPjwYVy5cgVt2rTB+PHjkZmZKXfT6s0d74nIVpj4EhEREZEisI4vERERESkCE18iIiIiUgQmvkRERESkCEx8iYiIiEgRmPgSERERkSIw8SUiIiIiRWDiS0RERESKwMSXiIiIiBSBiS8RERERKQITXyIiIiJSBCa+RERERKQITHyJiIiISBGY+BIRERGRIjDxJSIiIiJFYOJLRERERIrAxJeIiIiIFIGJLxEREREpAhNfIiIiIlIEJr5EREREpAhMfImIiIhIEZj4EhEREZEiMPElIiIiIkVg4ktEREREisDEl4iIiIgUgYkvERERESkCE18iIiIiUgQmvkRERESkCEx8iYiIiEgRmPgSERERkSIw8SUiIiIiRfCQuwHOTq/X49SpU/Dz84NKpZK7OUTkhoQQKC0tRWRkJNRq9+uPYBwlInuzNo4y8a3FqVOn0Lx5c7mbQUQKcPz4cURHR8vdDJtjHCUiR6ktjjLxtUCr1UKr1aKyshLA9W+kv7+/zK0iIndUUlKC5s2bw8/PT+6m2IXhvhhHicherI2jKiGEcFCbXFJJSQkCAgJQXFzMgE1EduGuccbQgaDT6fDHH3+43f0RkfOwNo6632AyIiJyChkZGdi/fz927dold1OIiAAw8SUiIiIihWDiS0RERESKwMSXiIiIiBSBiS8RERERKQITXyIiIiJSBCa+RERERKQITHyJiIiISBGY+BIRERGRIigi8V2zZg3atWuHtm3b4u2335a7OUREiqDVahEbG4tu3brJ3RQiIgAKWLK4srISsbGx2Lx5MwICAtC1a1ds27YNQUFBVh3vrkuJEpHzcPc44+73R0Ty45LFf9u5cyc6duyIqKgo+Pr6IjU1FevXr5e7WURERETkYE6f+G7duhVpaWmIjIyESqXC6tWrTfbRarWIiYmBj48PkpKSsHPnTum9U6dOISoqSnodFRWFkydPOqLpRG4vJiYGAwcOlLsZslGpVJgxY4bczSAiF8Y46tg46uGwK9VTeXk54uLiMGbMGAwdOtTk/ZUrVyIrKwuLFi1CUlISsrOzkZKSgoMHDyI0NFSGFgMJixNQWFYovQ73DUfuI7mytIVqV/3zklN9f1ZycnIwevRoo20hISHo2LEjJk+ejNTUVFs1kcghGEddC+MouQqnT3xTU1Nr/GGbP38+xo0bJ/2wLlq0CGvXrsXSpUsxZcoUREZGGvXwnjx5EomJiRbPV1FRgYqKCul1SUlJndtcWFaIk6XsVXYV7vR5vfDCC2jVqhWEECgqKkJOTg769++PL7/8UtE9CuR63On3Ugnc6fNiHHVvTp/41uTq1avYvXs3pk6dKm1Tq9VITk7G9u3bAQCJiYn49ddfcfLkSQQEBODrr7/Gf/7zH4vnnDVrFp5//nm7t52cj1qlRoRvhCzXLigrgF7oG3ye1NRUJCQkSK/Hjh2LsLAwfPjhhy4bsMvLy9GkSRO5m0FEVmAcdU6Mo1UIFwJAfPbZZ9LrkydPCgBi27ZtRvs9/fTTIjExUXr9+eefi7Zt24rWrVuL//73vzVe48qVK6K4uFj6On78uAAgiouLrW7nl0+vFlv/b5P09eXTq60+lhwval6UwAyIqHlRLtuGZcuWCQBi165dRtv1er3w9/cXDz30kLTt1VdfFd27dxeBgYHCx8dH3HrrrWLVqlVmz/vuu++Kbt26iUaNGommTZuKnj17im+++UZ6v2XLlmLAgAFGx+Tk5AiNRiOeeuopadvZs2fFv/71L+Hn5ycCAgLEQw89JPLy8gQAsWzZMmm/9PR00aRJE3H48GGRmpoqfH19xb333iuEEKKsrExkZWWJ6Oho4eXlJW6++Wbx6quvCr1eLx2fn59vck4DAGL69OnS6+nTpwsA4tChQyI9PV0EBAQIf39/MWrUKFFeXm507JUrV8SkSZNEcHCw8PX1FWlpaVJsqHrO+iouLq5znHEl9bk/w++E4UvO30+qHeMo46irxFGX7vG11qBBgzBo0CCr9vX29oa3t3eDrheob4YQESK91ug1DTofkbWKi4tx9uxZCCFw+vRpLFiwAGVlZfjXv/4l7fP6669j0KBBGDlyJK5evYoVK1bggQcewJo1azBgwABpv+effx4zZszA7bffjhdeeAFeXl7YsWMHNm3ahHvuucfs9RcvXozHHnsMzz77LF566SUAgF6vR1paGnbu3Inx48ejffv2+Pzzz5Genm72HJWVlUhJSUGPHj0wd+5cNG7cGEIIDBo0CJs3b8bYsWMRHx+Pb775Bk8//TROnjyJ1157rd7fs2HDhqFVq1aYNWsW9uzZg7fffhuhoaF45ZVXpH0efvhhvPfeexgxYgRuv/12bNq0yeh7RUTug3G07lwqjjY4xXYgVOvxraioEBqNxmibEEI89NBDYtCgQQ261ptvvik6dOggbr755jr3VPz45Bbxx6T90tePT25pUFvIvtypp6L6l7e3t8jJyTHa99KlS0avr169Kjp16iT69OkjbTt06JBQq9ViyJAhQqfTGe1ftWegak/F66+/LlQqlXjxxReN9v/kk08EAJGdnS1t0+l0ok+fPmZ7KgCIKVOmGJ1j9erVAoB46aWXjLbff//9QqVSicOHDwsh6tdTMWbMGKP9hgwZIoKCgqTXhh6Vxx9/3Gi/ESNGsMfXSuzxdX+Mo4yjVTlzHHX6cmY18fLyQteuXbFx40Zpm16vx8aNG9G9e/cGnTsjIwP79+/Hrl27GtpMIofRarXYsGEDNmzYgPfeew+9e/fGww8/jE8//VTap1GjRtL/X7hwAcXFxejZsyf27NkjbV+9ejX0ej2mTZsGtdo4TKhUKpPrzpkzBxMnTsQrr7yC5557zui9devWwdPTE+PGjZO2qdVqZGRkWLyP8ePHG73+6quvoNFo8MQTTxhtf/LJJyGEwNdff23xXLV57LHHjF737NkT586dkya2fvXVVwBgcu1JkybV+5pE5LwYR+vOleKo0w91KCsrw+HDh6XX+fn5yMvLQ2BgIFq0aIGsrCykp6cjISEBiYmJyM7ORnl5uUlJEiIlSExMNJqU8c9//hNdunRBZmYmBg4cCC8vL6xZswYvvfQS8vLyjCqYVA3Ef/75J9RqNWJjY2u95pYtW7B27Vo888wzePrpp03eP3r0KCIiItC4cWOj7W3atDF7Pg8PD0RHR5ucIzIyEn5+fkbbO3ToIL1fXy1atDB63axZMwDX/5j5+/vj6NGjUKvVaN26tdF+7dq1q/c1XdGaNWvw5JNPQq/X45lnnsHDDz9s1+stKtQioPLG6kvF5XWvsENUH4yjdedKcdTpe3xzc3PRpUsXdOnSBQCQlZWFLl26YNq0aQCA4cOHY+7cuZg2bRri4+ORl5eHdevWISwsrEHX5Rrz5A7UajV69+6NgoICHDp0CN9//z0GDRoEHx8fvPXWW/jqq6+wYcMGjBgxAqKeq5d37NgR7dq1w7vvvov8/PwGt9nb29ukd8Ra5npRAECn01k8RqMxPwa/vt8Pd1RZWYmsrCxs2rQJe/fuxauvvopz587Z9ZqB+mYIF+HSV6C+mV2vR2QJ4+h17hJHnT7x7dWrF4QQJl85OTnSPpmZmTh69CgqKiqwY8cOJCUlNfi6HOpA7qKyshLA9acnn3zyCXx8fPDNN99gzJgxSE1NRXJysskxrVu3hl6vx/79+2s9f3BwML799lt4enqib9++OHXqlNH7LVu2REFBAS5dumS0veqTnNq0bNkSp06dQmlpqdH233//XXofuNHLcPHiRaP9GtKT0bJlS+j1evz5559G2w8ePFjvc7oaLv1OSsc46j5x1OkTXyKqv2vXrmH9+vXw8vJChw4doNFooFKpjP7lfuTIEZOlwAcPHgy1Wo0XXngBer1xXUxz/4KPjo7Gt99+i8uXL+Puu+826g1MSUnBtWvXsGTJEmmbXq+HVqu1+j769+8PnU6HN99802j7a6+9BpVKJS1y4+/vj+DgYGzdutVov7feesvqa1VnOPcbb7xhtD07O7ve53Q0Lv1OVH+Mo9e5Sxx1+jG+ctFqtdBqtTV27RM5m6+//lr61/vp06fxwQcf4NChQ5gyZQr8/f0xYMAAzJ8/H/369cOIESNw+vRpaLVatGnTBvv27ZPO06ZNG/z73//Giy++iJ49e2Lo0KHw9vbGrl27EBkZiVmzZplcu02bNli/fj169eqFlJQUbNq0Cf7+/hg8eDASExPx5JNP4vDhw2jfvj2++OILnD9/HoDlx2pVpaWloXfv3vj3v/+NI0eOIC4uDuvXr8fnn3+OSZMmGY0be/jhhzF79mw8/PDDSEhIwNatW/HHH3/U+3saHx+Pf/7zn3jrrbdQXFyM22+/HRs3bqxTT4vcXHHpdyK5MI66dxxl4mtBRkYGMjIyUFJSgoCAALmbQw5QUFaA6PnRte9op2vbgmHsOwD4+Pigffv2WLhwIR599FEAQJ8+ffDOO+9g9uzZmDRpElq1aoVXXnkFR44cMQrYwI1lOxcsWIB///vfaNy4MTp37owHH3zQ4vVvueUWfP3110hOTkZaWhrWrVuHRo0aYe3atZg4cSKWL18OtVqNIUOGYPr06bjjjjvg4+NT632p1Wp88cUXmDZtGlauXIlly5YhJiYGr776Kp588kmT78GZM2fw8ccf46OPPkJqaiq+/vrrBiVwS5cuRUhICN5//32sXr0affr0wdq1a9G8efN6n9ORXHHpd3JNjKOMo5Y4SxxVCWcceexEDIlvcXEx/P39az8AwLantiJEd2MBizOaM7h97p32aiI1UPT8aKdZYz7KLwonsk7I3QyHWL16NYYMGYIffvgBd9xxh9zNkVV94kx9qVQqfPbZZxg8eDCA60u/N27cGB9//LG0DQDS09Nx8eJFfP7556isrESHDh3w3XffISAgAF27dsW2bdsQFBRk9hozZswwu/Q746j7YhyVB+PoDdbGUfb4kuKF+4bL3QSJM7XFli5fvmxU91Kn02HBggXw9/fHrbfeKmPL6OzZs9DpdCaVcMLCwqTHvR4eHpg3bx569+4NvV6PyZMnW0x6AWDq1KnIysqSXpeUlLhM7zjVjzPFLmdqiy0xjtoGE18LOMZXOXIfyZW7CW5vwoQJuHz5Mrp3746Kigp8+umn2LZtG2bOnGkUyMl51Wfpd8ZR5WActT/GUdtg4msBx/gS2U6fPn0wb948rFmzBleuXEGbNm2wYMECZGZmyt00xQsODoZGo0FRUZHR9qKiIoSHN6znjHGUyHYYR22Dia8DHZuXj1OFp6AXN3o/zqsvYEabF/mvZXJrI0aMwIgRI+RuBplRdel3wxhfw9Lv/INK5DwYR22Dia8D6UorEVQZaLxNr0NhWaFMLSIiJZBr6XcOdSAiZ8PE1wJ7Bmwdrp9TA/NL/BER2VJubi569+4tvTZMPEtPT0dOTg6GDx+OM2fOYNq0aSgsLER8fLxNln7nUAcicjZMfC2wZ8A+ozoDjVpjVKqHiMheDEu/1yQzM5NDG4jI7XHJYiIiIiJSBCa+RERkF1qtFrGxsejWrZvcTSEiAsDEl4iI7CQjIwP79+/Hrl275G4KEREAJr5EREREpBBMfC3gIzpyRzExMRg1apTczQAAHDlyBCqVCjk5OXI3heyEcZTcEeOoa2NVBwtYhkc5js3Lh660Uu5mAAA0fh5o8WSreh37yy+/4Pnnn8euXbtQVFSEoKAgxMbGYtCgQZgwYYKNW0pUO8ZR5WAcJVfBxJcUT1daicpi5wjY9bVt2zb07t0bLVq0wLhx4xAeHo7jx4/jp59+wuuvvy4F7IMHD0Kt5oMecg/Vk62GJDzUMIyj5CqY+BIZqAAPf3l+JSpLKoGay6zW6OWXX0ZAQAB27dqFpk2bGr13+vRp6f+9vb3rfxEiJ+MOyZbbYRwlJ8fE1wFCdCHIn3Ho+i8lOS0Pfw+0mtFWlmvnzzjUoD/gf/75Jzp27GgSrAEgNDRU+v+YmBj06tXLaDzYvn37MGHCBOzcuRNBQUF47LHHEBUVhTFjxiA/Px8xMTHSsZ06dcKUKVOQlZWFffv2ITIyEjNmzMBDDz0kne/8+fOYOXMmvvnmG+Tn50OtVuOOO+7A7NmzERcXV+97JCLnxzjKOOrsmPg6SE2/jAVlBYieH41w33DkPpLrwFaRu2jZsiW2b9+OX3/9FZ06dbL6uJMnT6J3795QqVSYOnUqmjRpgrfffttij8bhw4dx//33Y+zYsUhPT8fSpUsxatQodO3aFR07dgQA/PXXX1i9ejUeeOABtGrVCkVFRfjvf/+Lu+66C/v370dkZKRN7pmcnz2XfieyNcZRZWDi60gq4Iz6DM7gLMIRJm3WCz1Olp6UsWHk6p566imkpqYiPj4eiYmJ6NmzJ/r27YvevXvD09PT4nGvvPIKLly4gD179iA+Ph4AMHr0aLRta77H5uDBg9i6dSt69uwJABg2bBiaN2+OZcuWYe7cuQCAW265BX/88YfRGLgHH3wQ7du3xzvvvIP//Oc/Nrprcnac3EauhHFUGTg62wJ7lOHx8PfAsMgRuM9vmLRNo9ZAreLHQA1z9913Y/v27Rg0aBB+/vlnzJkzBykpKYiKisIXX3xh8bh169ahe/fuUrAGgMDAQIwcOdLs/rGxsVKwBoCQkBC0a9cOf/31l7TN29tbCtY6nQ7nzp2Dr68v2rVrhz179jTwTomI7INxVBmYcVngqBWHInwjEOEbYddrkDJ069YNn376KS5cuICdO3di6tSpKC0txf3334/9+/ebPebo0aNo06aNyXZz2wCgRYsWJtuaNWuGCxcuSK/1ej1ee+01tG3bFt7e3ggODkZISAj27duH4uLiet4dUe0Mw8YSFifI3RRyUYyj7o+JL5Gb8fLyQrdu3TBz5kwsXLgQ165dw6pVq2xybo1GY3a7EDemUs+cORNZWVm488478d577+Gbb77Bhg0b0LFjR+j1epu0g5Tt2Lx8sxOGdXodTpaeRGFZoUwtI3fBOOq+OMaXyI0lJFzv+SooKDD7fsuWLXH48GGT7ea2Wevjjz9G79698c477xhtv3jxIoKDg+t9XnI99prcVlsZM04YJltiHHUv7PF1oIKyAhSUGf/iVJZU4qNTH+CT0o9kahW5g82bNxv1Fhh89dVXAIB27dqZPS4lJQXbt29HXl6etO38+fN4//33690WjUZj0pZVq1bh5ElO4FQauw8ZUwFnNGeklxr19Z40w4Rh9vxSXTCOKgN7fB1Ip9dBL6o9ohDX6/zqVCz3Q/U3YcIEXLp0CUOGDEH79u1x9epVbNu2DStXrkRMTAxGjx5t9rjJkyfjvffew913340JEyZIZXhatGiB8+fPQ6VS1bktAwcOxAsvvIDRo0fj9ttvxy+//IL3338fN910U0Nvk8iIh78HhvmPwIcn3kW4CIdapUGUXxQKygpMYy1RLRhHlYGJr4OpVWpE+Eag9EopInwjGrzSDNlOZUkl8mccku3aDTF37lysWrUKX331FRYvXoyrV6+iRYsWePzxx/Hcc8+ZLcgOAM2bN8fmzZvxxBNPYObMmQgJCUFGRgaaNGmCJ554Aj4+PnVuy7PPPovy8nJ88MEHWLlyJW699VasXbsWU6ZMadA9EtUmrEkoTmSdQPT8aJaIlAnjKOOos2Pi62ARvhE4kXVCet3QlWbIhkTNC404s379+qFfv3617nfkyBGTbfHx8di6davRtkmTJsHHx8doLJm5YwHgu+++M3rt7e2NuXPnSvUoLe0XExNj9rEiEbkwxlEJ46hzYuJLiqfxc55fAznacvnyZTRq1Eh6fe7cObz77rvo0aOHxdnHRERVMY4yjroK5/lJJZJJiydbyd0EWXXv3h29evVChw4dUFRUhHfeeQclJSVcGYiIrMY4yjjqKpj4WsA15kkp+vfvj48//hiLFy+GSqXCrbfeinfeeQd33nmn3E0jInIJjKOug4mvBVxjnpRi5syZmDlzptzNIDdkrw6EovLTCELg9RKR6hslIg0Tqz4q+wCFKMITfv9n0+sSWcI46jpYx5eIiOzCXnV89eJ6Im1SIvLviVUhuhCE6Fnkn4hMMfElIiKXFeUXhWKPEpzzOA+PAA+g7iVTiUhBONSBiIhckkatMSoPCbBEJBHVjD2+RERERKQI7PG1s0JVobR+/Bmclbk1RERERMrFxNeOClWFuDOgD6L8ogAAJ0tPIgpRMreKiIiISJk41IGIiIiIFIGJLxEREREpAhNfJxEiQvDRqQ9wbF6+3E0hIiIicktMfJ2EBhqE6EKgK2UZHiJyD1qtFrGxsejWrZvcTSEiAqCQxHfIkCFo1qwZ7r//frmbYkLj54EzmjPQwbZLehIRyc2WK7cF6gKRP+MQn4oRUYMoIvGdOHEi/ve//8ndDLNaPNkKwyJH4IzqjNxNISJyWhpoUFlcyadiRNQgikh8e/XqBT8/P7mbQURE9VCoKqzzUzHOmyAic2RPfLdu3Yq0tDRERkZCpVJh9erVJvtotVrExMTAx8cHSUlJ2Llzp+MbSkREDmeoh35ec75Ox3HeBBGZI3viW15ejri4OGi1WrPvr1y5EllZWZg+fTr27NmDuLg4pKSk4PTp09I+8fHx6NSpk8nXqVOnHHUbRETkBDhvgohqIvvKbampqUhNTbX4/vz58zFu3DiMHj0aALBo0SKsXbsWS5cuxZQpUwAAeXl5NmtPRUUFKioqpNclJSU2OzcREdlXiydb4fb5PfHhiXcRLsLlbg4RORnZe3xrcvXqVezevRvJycnSNrVajeTkZGzfvt0u15w1axYCAgKkr+bNm9vlOkRERETkWE6d+J49exY6nQ5hYWFG28PCwlBYWGj1eZKTk/HAAw/gq6++QnR0dI1J89SpU1FcXCx9HT9+vN7tJyIieRWUFSB6fjQSFifI3RQicgKyD3VwhG+//dbqfb29veHt7Q2tVgutVgudjuPEiIhclU6vw8nSk3I3g4ichFP3+AYHB0Oj0aCoqMhoe1FREcLD7Tt2y5aF14mIyHHCfcOhUWvkbgYROSGnTny9vLzQtWtXbNy4Udqm1+uxceNGdO/eXcaWEREpi7OsgFlZUolAXWCN++Q+kosI3wgAYAJMREZkT3zLysqQl5cnVWbIz89HXl4ejh07BgDIysrCkiVLsHz5chw4cADjx49HeXm5VOXBXuRaY57j0YjIGTnNCpjieo1eIqL6kH2Mb25uLnr37i29zsrKAgCkp6cjJycHw4cPx5kzZzBt2jQUFhYiPj4e69atM5nwZmsZGRnIyMhASUkJAgIC7HqtqjgejYicUa9evfDdd9/Jdv3z6gtSL25BWQF0eh2K1Sw3SUR1I3uPb69evSCEMPnKycmR9snMzMTRo0dRUVGBHTt2ICkpSb4G20HV8WghIgRbizdhUaH5BT2IiKpTwgqYj4VnoNWMtmg1oy2GRY7AnQF98Fh4htzNIiIXI3uPL10fj5Y/4xAqiyuhgQbhIhwaPR/lEZF1DCtgjhkzBkOHDjV537AC5qJFi5CUlITs7GykpKTg4MGDCA0NBXB9BczKStPlfdevX4/IyEi734O9BOoCsbV4E4rL2TtMREx8LXJ0OTON3/WPoqK4guPXiKhOuAKmZexMIKKqZB/q4KwcXc6sxZOt0GpGW5zXnHfI9YhIGZS6AqbGzwMeAR7QgbXYiegGJr5ERG5MqStgsjOBiMzhUAcLuHIbEdENXAGTiNwBe3wt4MptROQOuAImEdENTHyJiNwYV8AkIrqBQx2IiFxcWVkZDh8+LL02rIAZGBiIFi1aICsrC+np6UhISEBiYiKys7MdtgImhzoQkTNh4ktE5OK4AiYRkXWY+FrAngoichWGFTBrkpmZiczMTAe1iIjIOTHxtUDunopAXSDyZxwCcL0eZYsnWzm8DURE7sIQUxlPiZSNia+T0kCDymLT5UOJiFyFMz05Y0wlIoBVHZzOefUFFKoKcUZzBlDJ3RoiovpzhnJmhpjKFdyICGCPr9N5LDwDJ0tPIsovCt+XbGYPBRFRAxhi6o+lWxCiC5G7OUQkM/b4EhGRXWi1WsTGxqJbt25yN4WICAATX4sYsImIGsYZhjoQEVXFxNcCBmwiIveh018f41tUflrmlhCRnDjGl4iIFKNpZQBLRRIpGBNfIiJyW+G+4df/p/j6f1jWjEjZONSBiIjswhnmSuQ+kosTWSdQ7FHCUpFExMTXFVSWVCJ/xiEcm5cvd1OIiKzmTHMlHgvPwJ0BfTAscgQ8/Pmwk0ipmPg6qYKyAhSUFVx/IYDK4kroSvl4joiIiKi+mPhaIPcjOr3QoxBFXHGIiIiIyEb4vMeCjIwMZGRkoKSkBAEBAQ67rjQRA8ADqn9AL/RccYiIiIjIBpj4OpncR3Kl/4+eH42TpSdlbA0RUf1ptVpotVrodHxqRUTOgUMdiIjILpxpchsREcDEl4iIFIoVc4iUh0MdiIhImf6umENEysHEl4iIFEXjd/1PX2VJJSBkbgwRORSHOhARkaK0eLIVWs1oy4UsiBSIiS8RERERKQITXxfCiRhERERE9cfE1wK5V24zi0sXE5ELccY4WlBWgOj50YieH42i8tNyN4eIHIyJrwXOVH/yvPoCPAI8AJXcLSEisp4zxVEDvdDjZOlJnCw9Cb3gwhpESsPE1wU8Fp7BiRhERA0Q7huOKL8oRPlFQa0y/tPHYWREysFMioiI3F6Ny8Gzni+RYrDHl4iIFInDyIiUh4kvEREpEoeRESkPE18XYJiFzBnIRERERPXHf+a6AMMsZM5AJiKyH8MkN+D6ssYtnmwlc4uIyNaY+DqxcN9wANd7fPVCL203BGcGZiIiG+IkNyK3x8TXiRlmIXMGMhGR/Wj8bvwprCypBISMjSEiu2Li60LOqy8gwjeCgZmIXIJWq4VWq4VO59zDtKo+OcufcYgdC0RuzO0ntx0/fhy9evVCbGwsOnfujFWrVsndpHrjDGQiciXOuHIbESmb22dQHh4eyM7ORnx8PAoLC9G1a1f0798fTZo0kbtpDcaJGERERETWc/vENyIiAhEREQCA8PBwBAcH4/z5826R+HKsLxGRfXASMZF7kn2ow9atW5GWlobIyEioVCqsXr3aZB+tVouYmBj4+PggKSkJO3furNe1du/eDZ1Oh+bNmzew1fLS+HnAI8CDKw4RETWAoUZ6wuIE0zf/7ljQlbJzgcidyN7jW15ejri4OIwZMwZDhw41eX/lypXIysrCokWLkJSUhOzsbKSkpODgwYMIDQ0FAMTHx6Oy0jQ4rV+/HpGRkQCA8+fP46GHHsKSJUvse0MOwIkYREQNZ6iRXpWhwgMnERO5J9kT39TUVKSmplp8f/78+Rg3bhxGjx4NAFi0aBHWrl2LpUuXYsqUKQCAvLy8Gq9RUVGBwYMHY8qUKbj99ttr3beiokJ6XVJSYuWdEBGRK7BUIx240bHATgUi9yT7UIeaXL16Fbt370ZycrK0Ta1WIzk5Gdu3b7fqHEIIjBo1Cn369MGDDz5Y6/6zZs1CQECA9OXqwyKIiMhY7iO5OJF1AhG+EXI3hYgczKkT37Nnz0Kn0yEsLMxoe1hYGAoLC606x48//oiVK1di9erViI+PR3x8PH755ReL+0+dOhXFxcXS1/Hjxxt0D0RERETkHGQf6mBvPXr0gF6vr33Hv3l7e8Pb29uOLSIiIiIiOTh1j29wcDA0Gg2KioqMthcVFSE8PNyu19ZqtYiNjUW3bt3seh0iInJehrJmx+bly90UIrIBp058vby80LVrV2zcuFHaptfrsXHjRnTv3t2u13bGFYcMpXcslt8hIrIDd1oBs85Y1ozIrcg+1KGsrAyHDx+WXufn5yMvLw+BgYFo0aIFsrKykJ6ejoSEBCQmJiI7Oxvl5eVSlQclMVd6x4DF1onIXtx5BUxLWNaMyD3Jnvjm5uaid+/e0uusrCwAQHp6OnJycjB8+HCcOXMG06ZNQ2FhIeLj47Fu3TqTCW+2ptVqodVqodPp7HodaxhK7wDmy+8A4CpuRGQ3br0CpgUsa0bknmQf6tCrVy8IIUy+cnJypH0yMzNx9OhRVFRUYMeOHUhKSrJ7u5xpqIOh9I658juGVdy4ghuRcnEFTCIi68ie+FLDtHiyFVrNaAsPf9k774lIJoYVMLVardn3DStgTp8+HXv27EFcXBxSUlJw+vRpaZ/4+Hh06tTJ5OvUqVPSPoYVMBcvXmz3eyIisgdmSxY401AHIqKacAXMhjFMHAauDy3LfSTXZB/OoyByD+zxtcCZhjoQEdUXV8CsnWHi8MnSkygss7A4Eqs7ELkFJr5ERG6MK2BaFu4bjii/KET5RUGtMv/nkPMoiNwLhzoQEVGN6rsCprMPGas6pCF6frTZcpHVqzsYhjwA4LAHIhfEHl8LuHIbEbkDOVfAdMshY38PeeCwByLXxB5fCzIyMpCRkYGSkhIEBATI3RyrVRbf6I0wYK8EkXJVXQFz8ODBAG6sgJmZmSlv41yIYUELgItaELkyJr5uiMXWiZTFWVfAdPahDnVRtfOAi1oQuS4mvu7KMBGDvRJEbs9ZV8B01SdnROS+mPi6KEPdSUs1Jw0LWrBXgsj9GVbArElmZiaHNhCR4jHxtcDZH9EZ6k4aVB1/ZnjNiRdERERENzDxtcBZH9GF+16fhV1QVgC9uFFeyNzkteqT3IiIHMnZOxCISHlYzszF5D6SixNZJxDhGyF3U4iIauSK5cwMw8ii50cjYXGC3M0hIhtjjy8REdHfqg8jIyL3wsSXiIjswpWGOhiGkQGmQ8mIyH1wqIMFXLmNiKhhXGmog2EYGYeSEbk3Jr4WuFLAJiIiIqLaMfElIiKqh8qS60vEH5uXL3dTiMhKHONLRERUH4KLBBG5Gia+CmDoldD4eZit90tEZA+uNLmtLgwLBlWWVErJb/W66Yy3RM6Jia+LM9ScBGBx+WL2ShCRHJx1IaCGMiS0+TMOSbGVMZbINTDxdXE11Zys3itBRER2pgLjLZETY+JrgbM/orOm5mT1XgnDkAcDPoojIrLM8ETN0tM0Q+dC1de60kr2/hI5MSa+Fjj7I7qqQTh6frR1Kw1xyAMRkdVqW8XNXMdB9bG+RORcmPgqQPVeCQ59ICJHcPYnZ5YYnqhxBTci98PEVwGq90pUnZBBRGQvzv7kzBLDEzWrn6YRkcvgAhZEREREpAjs8SUiIrKx6rV9OZmYyDkw8SUiIrIDDikjcj5MfImIiGpg1UJBROQSmPgSERHVoLayZkTkOpj4EhERmWHNQkHVmZSP5HAHIqfCxNeN1LbKEBGRI7lqHV+D+iwUxPKRRM6Nia8Frhiw6/o4ruoSxpxxTES25qp1fInIfbGOrwUZGRnYv38/du3aJXdTahXuG44ovyioVXX8OP9ewriyuBK6UvZIEBERkXtjj68bqOsqQ1XHoHH5YiIiIlIKJr4KVHVIA8efERERkVIw8SUAxuN9AY75JSIyp76TiKuv5AYwzhLJgYkvXSdYdoeIqDYNqenLGEskPya+CmdSc5JjfomITBhq+lpbz9ci1d//ZZwlkgUTXzdUl+U1WXOSiKh2dZ1EbImH//U/u5XFldIQMw55IHIcJr5uiMtrEhG5AA4xI3I4qxPfrKwss9sDAgJw8803Y+jQofD29rZZw6ju6rO8JhE5jqU46uPjAwCoqKhwZHPszpYLAVV9kuXq/7A3DDHj0DIix7M68d27d6/Z7RcvXsThw4fxn//8B5s2bUKLFi1s1jiqm/osr0lEjmMpjp47dw4AkJSUhO+++85t4qgtV25z1SdZ1edRVB3WwKFlRI5ndeK7efNmi++VlJRg5MiRmDJlCj744AObNMxWLl68iOTkZFRWVqKyshITJ07EuHHjHNqGgrICh16PiJyTpThqSAzbtWvnlHFUblF+UQCc60mWtXMprBm7y1JnRI5jkzG+/v7++M9//oMHHnjAFqezKT8/P2zduhWNGzdGeXk5OnXqhKFDhyIoKMhhbXCWQE1Ezm3y5MkYNWqU3M1wKhq1BieyTgBwridZtu6BZs8vkWPYbHJbcHAwzp8/b6vT2YxGo0Hjxo0BXB8/J4SAEI4bVGXoqTCoOg6XiKiqwMBAp4yjdINd51Kw1BmR3altdaKffvoJrVu3rvNxW7duRVpaGiIjI6FSqbB69WqTfbRaLWJiYuDj44OkpCTs3LmzTte4ePEi4uLiEB0djaeffhrBwcF1bmd9GHoqqn7VZaUfIlKW3NzcesVRcpzcR3KleB7hG2HTc3v4e0jlzojIPqz+Ddu3b5/Z7cXFxdi9ezdmzpyJ6dOn17kB5eXliIuLw5gxYzB06FCT91euXImsrCwsWrQISUlJyM7ORkpKCg4ePIjQ0FAAQHx8PCorTR8TrV+/HpGRkWjatCl+/vlnFBUVYejQobj//vsRFhZW57YqCetLEtmepTh66tQpAMCUKVMwY8YMB7aIiEhZrE584+PjoVKpzA4TCA4ORlZWFh5//PE6NyA1NRWpqakW358/fz7GjRuH0aNHAwAWLVqEtWvXYunSpZgyZQoAIC8vz6prhYWFIS4uDt9//z3uv/9+s/tUVFQYlRQqKSmx8k6cU33XlWd9SSLbqymOAterINQnjhIRkXWsTnzz8/PNbvf390ezZs1s1qCqrl69it27d2Pq1KnSNrVajeTkZGzfvt2qcxQVFaFx48bw8/NDcXExtm7divHjx1vcf9asWXj++ecb3HZnUdcJGKwvSWQ/luIoAMTExCArKwsqlcriPkRE1DBWJ74tW7a0ZzvMOnv2LHQ6ncmwhLCwMPz+++9WnePo0aN45JFHpEltEyZMwC233GJx/6lTpxoVmS8pKUHz5s3rdwMyqu+68tXrSxqGPAAsr0PUUJbiqKs/WSIichU2G0VfUFCAa9euOV3h9cTERKuHQgCAt7e3W6xAZ6t15TnkgchxCgsLcfHiRaeLo0RE7sJmVR369OmDVq1s2xsYHBwMjUaDoqIio+1FRUUID7dvWTCtVovY2Fh069bNrtdxVho/D3gEXP8Cn7wSOURaWprN46gtXLx4EQkJCYiPj0enTp2wZMkSuZvkVAxzKRIWJ9TpuKpx1iPAw2SVNyKyPZv9lv3vf//Djh07bHU6AICXlxe6du2KjRs3YvDgwQAAvV6PjRs3IjMz06bXqs6WS226oqpDGrisJpFjLFq0CL/99pvczTDhDAsBObP6LmZhbuhY9RXciMi2GtzjW1paisWLFyMjIwMTJ06s8/FlZWXIy8uThiPk5+cjLy8Px44dAwBkZWVhyZIlWL58OQ4cOIDx48ejvLxcqvJAROTqSktLAQBPPfVUveKovcm9EJCzCvcNR5RfFNQqmz08lRjmVxybZ3lCJBHVXb1/W7du3Yr09HRERERg7ty56NOnD3766ac6nyc3NxddunRBly5dAFxPdLt06YJp06YBAIYPH465c+di2rRpiI+PR15eHtatW2f3OrxKH+pARPZniKPt2rUDANx55531iqPuvBCQMzMsZmHrhSwASPMrdKV82kZkS3Ua6lBYWIicnBy88847KCkpwbBhw1BRUYHVq1cjNja2Xg3o1atXrT0HmZmZdh/aUJ3ShzqYw0UtiBrOUhwFgOeffx7+/v51PicXAnIOhrG+AOpeO/1vLClJZF9WJ75paWnYunUrBgwYgOzsbPTr1w8ajQaLFi2yZ/vIRmwRkFnhgahh7BVHuRCQc6jvWN+qqpeUrMmxeflGPcLslCCqndWJ79dff40nnngC48ePR9u2be3ZJqeg1Wqh1Wqh0+nkbopNNCQgV++BqCyuNJqAwWBLZB054igXArI/Q910oO610xtCV1rJzgiiOrJ6jO8PP/yA0tJSdO3aFUlJSXjzzTdx9uxZe7ZNVhkZGdi/fz927dold1MaxDD5oiETMFo82QqtZrSFh/+NfydVFldKXxUnriB/xiFOxCCqhRxxtKaFgAoLC606x9GjR9GzZ0/ExcWhZ8+eVi0EVFxcLH0dP368Qffg7Axjfe023peIbMbqTOi2227DkiVLUFBQgEcffRQrVqxAZGQk9Ho9NmzYIM1KJufiqIBsSII5EYPIspriKACnjaOGhYB+/vln7Nu3D48++miN+3t7e8Pf3x/vvvsubrvtNvTt29dBLSUiqlmduwCbNGmCMWPG4IcffsAvv/yCJ598ErNnz0ZoaCgGDRpkjzaSE+MiF0R1Vz2OGibvtmnTxuZxVM6FgNzlyRkRuY8GFR9s164d5syZgxMnTuDDDz+0VZucAsuZ1c4jwAOtZrQ1GQZBRNZr164dXnzxRQDAO++8Y/PzV10IyMCwEFD37t1tfj0iImdmk2xFo9Fg8ODB0upq7oDlzIjI0QYOHIgRI0bU+biysjIcPnxYem1YCCgwMBAtWrRAVlYW0tPTkZCQgMTERGRnZztkISB3myQsh7pMJjaUnKxtPyIlYzcdEZGLy83NRe/evaXXWVlZAID09HTk5ORg+PDhOHPmDKZNm4bCwkLEx8c7ZCEgdiDYhtWVG1hykqhWTHwVqL41fQ1lzSy9JiJ5OOtCQEpmiLP1rpteRx4BXPiCyBrMXCxw50d09a3py8dmRETWscViFtYyzLcArFv4gkjJGjS5zZ2542xkW9T0JSKylhInCRvibENjrMbPQ6qaY+jNJaKG42+TglR93BY9P9ouvRFc1Y2IDJQ4xtcQZxsaY6vHTfbkEtkGE1+yOQZnIrKHqksDm3tNRFQbJr5kd8fm5Rut6MZeYCJlsPVcCUdMEiMi98aBnmR3utJKaUljLmtMpBzuOFeCiFwbe3wtcOeqDvZQvbQZhzsQEdW/fKQlVRepYJwlqjsmvhYoZVKGrWpNWpqIUVnCwExEymXzsmZcpIKoQZj4Kpzda02ykDoRKVDViXcFZQXQC32Dzlf1qRoXqSCqPya+CmUIyrYIyOaYW9WNvRREyqLkIWO2Lh9Z9akaS5sR1R8TX4WyVa1JS8xVbWCwJlIWpQwZIyLXwcSXZFO9zBnAUmdE5L5sPdGNiOqOiS/JxlDmjIhICew+p4KIasXE1wIlj01zONXf/+VkDSJyQ7ae6NZQXFSIlIyJrwVKG5sm5yM4D//rP4bs/SVyL+xAuM7WE90aik/bSMmY+BIAPoIjIttTWgcCETk/Jr4K52yP4IiIlMBWiwdZUnWFN6Dm4QyGfTnkgZSAia/COdsjOCIiJXDE4kFWD2fganCkIEx8iYiIHMQWiwdVXyCo6uvq79W2yptHgAdXgiNFYeJLRETkILZYPKim4QjV36tp4SCPAA+0mtGWiwuRojDxJSIikgkXtSByLCa+ZMLeky6IiOg6R1XUqTqBjUjJ+BtAJljajIhsgXV8LXN4RR1OYCMCAKjlboCz0mq1iI2NRbdu3eRuisOE+4Yjyi8KahV/LIio4TIyMrB//37s2rVL7qY4ndxHcnEi6wROZJ1AhG8EgBtP2xIWJ9jsOho/D3gEeNxYIZNI4ZjhWKDEgG0IxIYgTEREjmN42lZYVmizc7Z4shVazWgrrZBJpHT8TSCnYk3R9errzFcWV17v0aiChdiJyFXYosQZEVmHiS85FyvGoZlbZ55j14jIVdmixJm1KkvqFiurdzSYw44GciVMfMkp1LXoulmGMWwsxE5EZF4d46O5jgYiV8bElyxyZH3JuhRdt8Qwho1BmojImLkyZnUqbaaCyThhrvhGroiJL1nEsmZERO6hoUMRPPyvr/JWFVd8I1fExJdMOLy+JBEREZEDMPElE1WHNBgmW3A1NyIix+AyxkT2w8SXrGLLYQ+VxddLllkzu7jqMpt1eVRX3+OIyHa4clv9cJgZkf1wAQuqkb1Wc6sstnJSxN/lzWorp2Oz44jIZpS4EFBDGOItV9Aksh/2+FKN7Fpf8u9ZwjXNNq7rrOH6HkdEJDdzw8wczWSBIGuezBUbLzwEsLavNczVSOb3zf4Uk/heunQJHTp0wAMPPIC5c+fK3RyC+VnCBoZf/LrOGq7vcUREVP+6vYy3dccayfJQzLOUl19+GbfddpvczSAiIrKaYaJbwuIEx15YBXgEeEhfVtX8VeHGQkJkPX7fHEoRPb6HDh3C77//jrS0NPz6669yN4eIiMgqck10q+mJXE3HAOz9rSt+3xxL9h7frVu3Ii0tDZGRkVCpVFi9erXJPlqtFjExMfDx8UFSUhJ27txZp2s89dRTmDVrlo1aTEREZF/2mlhMpHSy/0aVl5cjLi4OWq3W7PsrV65EVlYWpk+fjj179iAuLg4pKSk4ffq0tE98fDw6depk8nXq1Cl8/vnnuPnmm3HzzTc76paIiIgaJPeRXJzIOoEI3wi5m0LkVmQf6pCamorU1FSL78+fPx/jxo3D6NGjAQCLFi3C2rVrsXTpUkyZMgUAkJeXZ/H4n376CStWrMCqVatQVlaGa9euwd/fH9OmTTO7f0VFBSoqKqTXJSUl9bgrIiIiInI2svf41uTq1avYvXs3kpOTpW1qtRrJycnYvn27VeeYNWsWjh8/jiNHjmDu3LkYN26cxaTXsH9AQID01bx58wbfhzsxTLSQZbIFEZFCMfYS2YbsPb41OXv2LHQ6HcLCwoy2h4WF4ffff7fLNadOnYqsrCzpdUlJCZPfKuSaaGFYiQ2o2wSA+taXrF5fkbUViUhOXM2NyDacOvG1tVGjRtW6j7e3N7y9vbnUZjXhvuHS/xeUFUAv9I5tgKj/jNf6HMf6ikSmWA/d8WSPvURuxqkT3+DgYGg0GhQVFRltLyoqQnh4uIWjbCMjIwMZGRkoKSlBQECAXa/lCmyxolD1OpDW1IWsuk+DVmMz1Ejkam5E9cZ66I5nLvYahj0A1xPjqvu4kvo+WTO34lldjidlc+rE18vLC127dsXGjRsxePBgAIBer8fGjRuRmZkpb+OozuoTkKoe05DV2FgnkahhWA/debjLsIf6PlnjEzlqCNknt5WVlSEvL0+qzJCfn4+8vDwcO3YMAJCVlYUlS5Zg+fLlOHDgAMaPH4/y8nKpyoO9aLVaxMbGolu3bna9DhFRQ7EeujIYavs6S31fjZ9H3Vd3s6W/V5fjqmdUF7L3+Obm5qJ3797Sa8PEsvT0dOTk5GD48OE4c+YMpk2bhsLCQsTHx2PdunUmE95sjUMdaucuj9uIXJ2hHvqYMWMwdOhQk/cN9dAXLVqEpKQkZGdnIyUlBQcPHkRoaCiA6/XQKytNe9HWr1+PXbt2SfXQt23bZvf7IfNsMeTMlsw9xas+mdieDKvLNeRpICmP7Ilvr169IETNAy8zMzM5tMEJucvjNiJXx3roRETWkf9ZCbkcZ3vcRkSWsR46EdENzFos4BhfywxLaXI5TSLnV1M99MLCQrtcc+rUqSguLpa+jh8/bpfrEBHVlexDHZwVx/gSEZliPXQicmXs8SUicmNy10Pfv38/du3aZdfrEBFZi4mvBRzqQETuoGo9dANDPfTu3bvL2DIiIsfjUAcLONShbk6WnpRKmxmwxBmRY5SVleHw4cPSa0M99MDAQLRo0QJZWVlIT09HQkICEhMTkZ2d7bB66BzqYF9Vy0oaMPYSWcbEl2yGpc2I5MF66MrFspJEdcPEl2zKUN5ML/Qyt4RIOVgPXXnCfU3HZxeUFTD2EtWCiS/ZlKG8GXsgiIjsx9xQBsNqbobhDxzyQGSKk9ss4OQ2IqKGYRyVh2H4Q2GZfeo0E7ky9vhawLFp1qn+uC3cN9zpg21lSaXRevKVxZXwCDD+Vahp3fdj8/KhKzV9X+PnYXbtenKs6p8PPxf5MI46liEeG4Y8VJ34xt5fouuY+FKDWHrc5tSEaWJbU6Jbna60sk77k2Px8yGlMsRjw5AHTnwjMsXEl+zG2caZafyq9eqWVAJV5wOp/v5vzXOEjPb38PcwPQ8RAWA5M7lUfRJXlwlvlSW2+wdj9SdrZvcx8w/U6k9s6vJEruo1rXnSY+7pEIBanxjV9zhXZO4Jp6vfGxNfshtn622o/ouaP+OQUQD18L/+62Btb6GHvwdazWhrch4iuo5DHeRRtaPB0PtrFVv+A97MkzVrmHtiY/V56nhNS0+HajtHfY9zRe74BI2JL9lc9XFmRETkvKo/DbO0rb7nqq5eT8lqeCJX9Zp8AmcndX0i6sSY+FrAR3T1V32cGRERyaumoWe2fGxtzbnq85SspidyVa/JJ3D2Udcnos6M5cwsyMjIwP79+7Fr1y65m0JERNQgLHFGdB0TXyIisgvW8ZVfuG84ovyipFU1iZSOvwlERGQXfHImv9xHcnEi64S0qiaR0jHxJSIiIiJFYOJLRERERIrAxJeIiIiIFIGJrwWclEFE1DCMo0TkbJj4WsBJGUREDcM4SkTOhgtYkN0ZCqcDMFs8nYiIHCdhcYJRPV/GZVISJr5kd4bC6UREJL/CskLGZFIsJr5kN+G+4dL/F5QVQC/0NS6bSURERGRPTHzJbqomttHzo3Gy9CR7f4mIiEg2THzJIQy9v4aeXyIicryCsgK5m0AkKya+5BCG3l9Dz2/VCW8nS08iyi/KaH8OhSAisj12PJDSMfElWVQf8sDhD0TuR6vVQqvVQqfTyd0Uxas658KAcZeUiIkvOZS5CW8GatX1stJVJ8EZjmHvL5HrycjIQEZGBkpKShAQECB3cxTNXAw1PIGrjuXOyJ0x8bWAPRX2YW7Cm0GEbwQAcBIcEZGMWO6M3BlXbrOAKw7JI9w3HFF+UYjyi5J6gImIiIhsgT2+JJvqY86qP06z9BiOiIhsq+rwhuqVHzj0jNwJE1+SDYMnEZFzqGl4A4eekTth4ktERKRgVXt41Sq10XwLQ6lJ1mAnd8HEl4iISMGqJrQRvhE4kXXCZB8OPSN3wcSXiIhIgczV9jW3jcidMPElIiJSIM6zICVivSgiIrILrVaL2NhYdOvWTe6mEBEBYOJLLsBQSqeo/LTcTSGiOmA9dCJyNhzqQE7PUEpHL7iKHhGRs+DSxuSKFJH4xsTEwN/fH2q1Gs2aNcPmzZvlbhJZwTDJgmV0iIicD5c2JlekiMQXALZt2wZfX1+5m0F1YOg5YBkdIiLnUHUVt+orvBG5AsUkvkRERNQwXMWNXJ3sk9u2bt2KtLQ0REZGQqVSYfXq1Sb7aLVaxMTEwMfHB0lJSdi5c2edrqFSqXDXXXehW7dueP/9923UciIiImUI9w1HlF+U2S8iVyJ7j295eTni4uIwZswYDB061OT9lStXIisrC4sWLUJSUhKys7ORkpKCgwcPIjQ0FAAQHx+PyspKk2PXr1+PyMhI/PDDD4iKikJBQQGSk5Nxyy23oHPnzna/NyIiIndQ06Q1DkcjVyJ74puamorU1FSL78+fPx/jxo3D6NGjAQCLFi3C2rVrsXTpUkyZMgUAkJeXV+M1oqKu/4s0IiIC/fv3x549eywmvhUVFaioqJBel5SU1OV2iIiIiMhJyT7UoSZXr17F7t27kZycLG1Tq9VITk7G9u3brTpHeXk5SktLAQBlZWXYtGkTOnbsaHH/WbNmISAgQPpq3rx5w26CbEanZzkzIiIiqj+nTnzPnj0LnU6HsLAwo+1hYWEoLCy0cJSxoqIi9OjRA3Fxcbjtttvw0EMP1biK0NSpU1FcXCx9HT9+vEH3QERERETOQfahDvZ200034eeff7Z6f29vb3h7e9uxRVRXhnq+mlINwE5fIlmwHjoRuQOnTnyDg4Oh0WhQVFRktL2oqAjh4eF2vbZWq4VWq4VOx0xLboZJFfkzDqGy2HQSIxE5BuuhE5Grc+qhDl5eXujatSs2btwobdPr9di4cSO6d+9u12tzjXkiIiIi9yJ74ltWVoa8vDypMkN+fj7y8vJw7NgxAEBWVhaWLFmC5cuX48CBAxg/fjzKy8ulKg9ERErHeuhERNaRfahDbm4uevfuLb3OysoCAKSnpyMnJwfDhw/HmTNnMG3aNBQWFiI+Ph7r1q0zmfBmaxzqQESugvXQyRlUXc443DfcbO3fhMUJeKNsPkIQ4ujmEQFwgsS3V69eEELUuE9mZiYyMzMd1KLrMjIykJGRgZKSEgQEBDj02kREdcF66OQMrFnOuLCskKUpSVayD3UgshVDb0PC4gSL71l6n8hdsR462VvV5YzVKqYV5Nxk7/F1Vhzq4Hp0ep3F3oaa3iNyZzXVQ//999+tOkdRURGGDBkCANDpdBg3blyt9dANw9aA6z2+TH7dV9UhDYbli0+WnpSGPRgYSlNaUlR+GmFNQu3SRiIDJr4WcKgDEdF19a2Hzg4EZatrZ4Ne8OeE7I/PJIiI3Jic9dBZFpLUKjWHP5BT4U8jEZEbk7MeOlGEbwQifCPkbgaRhEMdLOAjOiJyFWVlZTh8+LD02lAPPTAwEC1atEBWVhbS09ORkJCAxMREZGdnO6QeOuMoETkbJr4WcIwvEbkKZ62HzjiqPNUnsIX7hqOwrFCm1hCZYuJLbqegrAAFZQUskE6K4az10El5zC1aUb26A5GcmPiS29ELPQukExE5mYKyghrf1+l17LQgu2PiS24lyu/66lIolrcdRMQxvmRML/S17sNOC7I3VnWwQKvVIjY2tsYi7eRcNGoNTmSdwImsE9CoNXI3h0jxWM6MAOOV3aL8ohifSVbs8bWAkzKIiIgarvq43/wZh1BZXGmyn0atYY8v2R17fImIyC745Ixsqaj8tNHrgrICJCxOkKk15KqY+BIRkV1wqAPZUvUljXV6HUulUZ1xqAO5DbWK48aIiFyVWqW53h3H0Q5kR+zxtYCP6FxPWJNQuZtARET1FNYklMsbk90x8bWAj+iIiIiI3AsTXyIisgs+OSMiZ8MxvkR/M6wqxFWDiGyDZSHJVqpXdKhNQVkBes7vLb0+WXryxgJHf/u4fCWCEGiT9pHrYOJL9DfWjyQick7VKzrURqfX4WTpSaNt1V/X9ZzkHpj4Ev1NWk2IsZCIyOWpVddHc1ZdKtncNlIWJr5EfzPMJja3ohAREbkWQ0yv2tNrbhspCye3WcBJGUREDcM4SkTOhomvBSxnRkTUMIyjRORsmPgSERERkSIw8SWyQlH5aUTPj0b0/Gip7FlBWYHRayIisg+dXme28o4hDicsTqjXOaufq65l08j1cHIbkRX04kZpHEOwNJTLYRk0IiJ56IXeZhPVdHoduwMVgB8xuSW1SmP0WipV1uDzqqVzadQaqTQOERHZj0atMYnjjMFUH/yJIbcU1iTU6HWEb4TJqj31EeEbIZXDqfr/RERkP+biLWMw1QcTXyIiIiJSBCa+RERkF6zjS0TOhokvERHZBev4EpGzYeJLRERERIrAxNcCPqIjIiIici9MfC3gIzoiIiIi98IFLEiREhYn4I2y+QhBiM3OWVBWgJ7ze0uvw33DkftIrnS9wrJCs+9Z09aqx1o63tr9iIjckT3iur1Ubath9U9XaLc7YOJLilRYVmjzFdcMK7lZul59Vxey9tiGXIOIyNXZI67bS9W2ukqb3QWHOhA1QLhvuNFKblF+UXZbSUitUlt1bmv3IyJyVxq1BuG+4XI3g5wQ/zoSNUDuI7lGK7mdyDpht5WErF2liKsZEZHSRfhGuMwwr+pLMZN9MfElIiIiIkVg4ktERHbBspBE5GyY+BIRkV2wLCQRORsmvkRERESkCEx8iYiIiEgRFJH45ufno3fv3oiNjcUtt9yC8vJyuZtERERERA6miAUsRo0ahZdeegk9e/bE+fPn4e3tLXeTiIiIiMjB3D7x/e233+Dp6YmePXsCAAIDA2VuERERERHJQfahDlu3bkVaWhoiIyOhUqmwevVqk320Wi1iYmLg4+ODpKQk7Ny50+rzHzp0CL6+vkhLS8Ott96KmTNn2rD1REREROQqZO/xLS8vR1xcHMaMGYOhQ4eavL9y5UpkZWVh0aJFSEpKQnZ2NlJSUnDw4EGEhoYCAOLj41FZWWly7Pr161FZWYnvv/8eeXl5CA0NRb9+/dCtWzfcfffddr83IiIiInIesie+qampSE1Ntfj+/PnzMW7cOIwePRoAsGjRIqxduxZLly7FlClTAAB5eXkWj4+KikJCQgKaN28OAOjfvz/y8vIsJr4VFRWoqKiQXpeUlNT1loiIiIjICck+1KEmV69exe7du5GcnCxtU6vVSE5Oxvbt2606R7du3XD69GlcuHABer0eW7duRYcOHSzuP2vWLAQEBEhfhoSZiIiIiFybUye+Z8+ehU6nQ1hYmNH2sLAwFBYWWnUODw8PzJw5E3feeSc6d+6Mtm3bYuDAgRb3nzp1KoqLi6Wv48ePN+geiIjcActCEpE7kH2ogyPUNpyiKm9vb5Y7c3MFZQV1Pkan19XrOtHzoxHuG17jfgmLE1BYZvkfcidLT9Z67sKywnrdlz1Uv59w33DkPpIrY4vsz9xn6G73zbKQ5MxsFf+qx/qCsgL0nN/baNtHZR8gBCHS66Ly09ALndE2c8dZ097qx50sPYkovyijfVw5ttT098FRcdSpE9/g4GBoNBoUFRUZbS8qKkJ4eM3JRENptVpotVrodHVPeMi56YXeYdcxl7RWV1hWaNV+NZ27rsfbU33ux9W5+z2zLCQ5O3vFdZ1eZ/K7XT051gudyTZzx9X3eu4UW2qKlY6Ko0491MHLywtdu3bFxo0bpW16vR4bN25E9+7d7XrtjIwM7N+/H7t27bLrdchxwn3DEeUXJX1p1Jo6HR/lF1Vr723V66hVdfv1UqvURu0zd3xN5zYcb00byT7UKnWdP3dbYFlIUqra4nr198N9w6Vt1ffVqDVm/y5Ujc3W/n5r1Bqj65r7svQ3yFwckSu2yMHe9yp7j29ZWRkOHz4svc7Pz0deXh4CAwPRokULZGVlIT09HQkJCUhMTER2djbKy8ulKg9E1qr+uCR/xiFUFpuWwTNHo9bgRNYJ6ThrrhM9P7pO/3qN8I2QrmHp+JrOXfX46PnRVl+XbCfCNwKA43toWBaSlKq2uF7TY/Lq+xp+f6v/XTCJrRdrb1f1eG7N9au3o2ockSu2yMHe9yp74pubm4vevW+MZ8nKygIApKenIycnB8OHD8eZM2cwbdo0FBYWIj4+HuvWrTOZ8GZrHOpARK6CZSGJiKwje795r169IIQw+crJyZH2yczMxNGjR1FRUYEdO3YgKSnJ7u3iUAcicgcsC0lEdIPsiS8REdkPy0ISEd0g+1AHZ8WhDkREN9SnLCTjKBE5G/b4WsChDkTkDuQsC8k4SkTOhokvEZEbk7MsJBGRs+FQByIiF+esZSE51IGInA0TXwsYsInIVThrWciMjAxkZGSgpKQEAQEBdr0WEZE1mPhawIBNRK7CUBayJpmZmcjMzHRQi4iInBPH+BIRERGRIjDxJSIiu9BqtYiNjUW3bt3kbgoREQAmvhYxYBMRNQzLmRGRs2HiawEDNhEREZF7YeJLRER2wSdnRORsWNWhFoaZ0iUlJVYfU15Rjka6RijXlNfpOKpZaUUZdBWVFt/XVHhI3+/q+1Z9z9L5NBXXfx3MXaPqZ2k4znDO6q8N9Ff0wBVA76m/vuHKjfPpPfXSvlX3M3d8bccYzm3NOR2hpnY7gjWfva3V9nnUxrBfbZUZXI2hOk5xcTGaNm3KOEoALMfymmKwufdqiuvW/N5b8zegXFUO/RXj2FpeUY4yUXZjH005dHqd0ba6XL/q8YbrATCJo4ZtjoypVb+fAKz+3lrSkL9rtbE2jqqEu0VaGztx4gSaN28udzOISAGOHz+O6OhouZthc4yjROQotcVRJr610Ov1OHXqFPz8/KBSqep9npKSEjRv3hzHjx+Hv7+/DVvoXJRwn0q4R0AZ9+ks9yiEQGlpKSIjI6FWu98INFvFUcB5PjNXwe+X9fi9qhtn+35ZG0c51KEWarXapj0w/v7+TvEDYm9KuE8l3COgjPt0hnt054VybB1HAef4zFwJv1/W4/eqbpzp+2VNHHW/rgUiIiIiIjOY+BIRERGRIjDxdRBvb29Mnz4d3t7ecjfFrpRwn0q4R0AZ96mEe3Q3/Mzqht8v6/F7VTeu+v3i5DYiIiIiUgT2+BIRERGRIjDxJSIiIiJFYOJLRERERIrAxJeIiIiIFIGJr4NotVrExMTAx8cHSUlJ2Llzp9xNqretW7ciLS0NkZGRUKlUWL16tdH7QghMmzYNERERaNSoEZKTk3Ho0CF5GtsAs2bNQrdu3eDn54fQ0FAMHjwYBw8eNNrnypUryMjIQFBQEHx9fXHfffehqKhIphbX3cKFC9G5c2epAHn37t3x9ddfS++7+v2ZM3v2bKhUKkyaNEna5o736Y7cKY7aklJisi0oIa7bkjv+jWDi6wArV65EVlYWpk+fjj179iAuLg4pKSk4ffq03E2rl/LycsTFxUGr1Zp9f86cOXjjjTewaNEi7NixA02aNEFKSgquXLni4JY2zJYtW5CRkYGffvoJGzZswLVr13DPPfegvLxc2uf//u//8OWXX2LVqlXYsmULTp06haFDh8rY6rqJjo7G7NmzsXv3buTm5qJPnz6499578dtvvwFw/furbteuXfjvf/+Lzp07G213t/t0R+4WR21JKTHZFpQQ123JLf9GCLK7xMREkZGRIb3W6XQiMjJSzJo1S8ZW2QYA8dlnn0mv9Xq9CA8PF6+++qq07eLFi8Lb21t8+OGHMrTQdk6fPi0AiC1btgghrt+Xp6enWLVqlbTPgQMHBACxfft2uZrZYM2aNRNvv/22291faWmpaNu2rdiwYYO46667xMSJE4UQ7vs5uht3jqO2pKSYbAtKieu25Op/I9jja2dXr17F7t27kZycLG1Tq9VITk7G9u3bZWyZfeTn56OwsNDofgMCApCUlOTy91tcXAwACAwMBADs3r0b165dM7rX9u3bo0WLFi55rzqdDitWrEB5eTm6d+/udveXkZGBAQMGGN0P4H6foztSWhy1JXeOybbg7nHdltzlb4SH3A1wd2fPnoVOp0NYWJjR9rCwMPz+++8ytcp+CgsLAcDs/Rrec0V6vR6TJk3CHXfcgU6dOgG4fq9eXl5o2rSp0b6udq+//PILunfvjitXrsDX1xefffYZYmNjkZeX5xb3BwArVqzAnj17sGvXLpP33OVzdGdKi6O25K4x2RbcOa7bkrv9jWDiS2SFjIwM/Prrr/jhhx/kborNtWvXDnl5eSguLsbHH3+M9PR0bNmyRe5m2czx48cxceJEbNiwAT4+PnI3h4ichDvHdVtyt78RHOpgZ8HBwdBoNCazHIuKihAeHi5Tq+zHcE/udL+ZmZlYs2YNNm/ejOjoaGl7eHg4rl69iosXLxrt72r36uXlhTZt2qBr166YNWsW4uLi8Prrr7vN/e3evRunT5/GrbfeCg8PD3h4eGDLli1444034OHhgbCwMLe4T3emtDhqS+4Yk23B3eO6Lbnb3wgmvnbm5eWFrl27YuPGjdI2vV6PjRs3onv37jK2zD5atWqF8PBwo/stKSnBjh07XO5+hRDIzMzEZ599hk2bNqFVq1ZG73ft2hWenp5G93rw4EEcO3bM5e61Kr1ej4qKCre5v759++KXX35BXl6e9JWQkICRI0dK/+8O9+nOlBZHbcmdYrItKDWu25LL/42Qe3adEqxYsUJ4e3uLnJwcsX//fvHII4+Ipk2bisLCQrmbVi+lpaVi7969Yu/evQKAmD9/vti7d684evSoEEKI2bNni6ZNm4rPP/9c7Nu3T9x7772iVatW4vLlyzK3vG7Gjx8vAgICxHfffScKCgqkr0uXLkn7PPbYY6JFixZi06ZNIjc3V3Tv3l10795dxlbXzZQpU8SWLVtEfn6+2Ldvn5gyZYpQqVRi/fr1QgjXvz9LqlZ1EMJ979OduFsctSWlxGRbUEJctyV3/BvBxNdBFixYIFq0aCG8vLxEYmKi+Omnn+RuUr1t3rxZADD5Sk9PF0JcL5/zn//8R4SFhQlvb2/Rt29fcfDgQXkbXQ/m7hGAWLZsmbTP5cuXxeOPPy6aNWsmGjduLIYMGSIKCgrka3QdjRkzRrRs2VJ4eXmJkJAQ0bdvXymgCeH692dJ9cTXXe/T3bhTHLUlpcRkW1BCXLcld/wboRJCCMf1LxMRERERyYNjfImIiIhIEZj4EhEREZEiMPElIiIiIkVg4ktEREREisDEl4iIiIgUgYkvERERESkCE18iIiIiUgQmvkRERESkCEx8iYiIiEgRmPiSTfTq1QuTJk2y+JqMnTt3DqGhoThy5IjcTXEb//jHPzBv3jy5m0FUK8ZLeTDuNpw7xFkmvm5o1KhRGDx4sKxt+PTTT/Hiiy/K2oaqRo8ejeeee07uZkhefvll3HvvvYiJibG4z6hRo6BSqTB79myj7atXr4ZKpbJzCxuusLAQEydORJs2beDj44OwsDDccccdWLhwIS5dumTVOdLS0tCvXz+z733//fdQqVTYt28fAOC5557Dyy+/jOLiYpvdA7k/xkvlMBd3GWeVF2eZ+JJdBAYGws/PT+5mAAB0Oh3WrFmDQYMGyd0UAMClS5fwzjvvYOzYsbXu6+Pjg1deeQUXLlywaRuuXr1q0/NV99dff6FLly5Yv349Zs6cib1792L79u2YPHky1qxZg2+//daq84wdOxYbNmzAiRMnTN5btmwZEhIS0LlzZwBAp06d0Lp1a7z33ns2vRcie3OmeOmuaoq7jLPKirNMfBVGr9dj1qxZaNWqFRo1aoS4uDh8/PHHRvusW7cOPXr0QNOmTREUFISBAwfizz//lN4vLy/HQw89BF9fX0RERJh97GHuUd4TTzyByZMnIzAwEOHh4ZgxY4bRMaWlpRg5ciSaNGmCiIgIvPbaa7U+ArTmfrZt2wZPT09069YNAHDzzTeje/fuuHz5srSPEAK33XYbpk6davY6hYWFUKlUeP3119GlSxf4+PigY8eO+OGHHyy2zZKvvvoK3t7euO2222rdNzk5GeHh4Zg1a1aN+1VUVOCJJ55AaGgofHx80KNHD+zatUt6v1evXsjMzMSkSZMQHByMlJQUafuECRMwadIkNGvWDGFhYViyZAnKy8sxevRo+Pn5oU2bNvj666/rdI+PP/44PDw8kJubi2HDhqFDhw646aabcO+992Lt2rVIS0uT9q3pMxw4cCBCQkKQk5NjdP6ysjKsWrXK5I9YWloaVqxYUae2ElnibvGyPr/vMTExyM7ONjpPfHy8UXtqiz/W3lN1joq71sRZa++xepy1V4wFGGfri4mvwsyaNQv/+9//sGjRIvz222/4v//7P/zrX//Cli1bpH3Ky8uRlZWF3NxcbNy4EWq1GkOGDIFerwcAPP3009iyZQs+//xzrF+/Ht999x327NlT67WXL1+OJk2aYMeOHZgzZw5eeOEFbNiwQXo/KysLP/74I7744gts2LAB33//fa3nteZ+vvjiC6SlpUmPrVauXIk9e/bgxx9/lPZ5//33cfToUTz77LNmr5OXlwcAWLp0KbKzs5GXl4cWLVpg5MiR0vfFWt9//z26du1q1b4ajQYzZ87EggULzP5r3GDy5Mn45JNPsHz5cuzZswdt2rRBSkoKzp8/L+2zfPlyeHl54ccff8SiRYuMtgcHB2Pnzp2YMGECxo8fjwceeAC333479uzZg3vuuQcPPvig1Y/Nzp07h/Xr1yMjIwNNmjQxu0/VR4g1fYYeHh546KGHkJOTAyGEdMyqVaug0+nwz3/+0+i8iYmJ2LlzJyoqKqxqK1FN3C1eGs5ry993wLr4Y809VeeouGtNnK3LPVaPs/b4njPONoAgt5Oeni7uvfdek+1XrlwRjRs3Ftu2bTPaPnbsWPHPf/7T4vnOnDkjAIhffvlFlJaWCi8vL/HRRx9J7587d040atRITJw4Udp21113mbzu0aOH0Xm7desmnnnmGSGEECUlJcLT01OsWrVKev/ixYuicePGRuepz/20bdtWrFmzxmifxMREsWDBAiGEEOXl5SI6Olq8/fbbFr8Hs2fPFp6eniI/P1/alpubKwCIY8eOiYULF4q4uDjRqVMn4enpKeLi4kRcXJx48803Tc517733ijFjxli8lkHVz/G2226Tjvnss89E1V/dsrIy4enpKd5//31p29WrV0VkZKSYM2eOEOL6979Lly4m16j+uVRWVoomTZqIBx98UNpWUFAgAIjt27fX2mYhhPjpp58EAPHpp58abQ8KChJNmjQRTZo0EZMnTxZCWPcZHjhwQAAQmzdvlt7v2bOn+Ne//mVy7Z9//lkAEEeOHLGqrURKiZfmzmvN73vLli3Fa6+9ZnSeuLg4MX36dCGEdfHHmnsyxxFx15o4W5d7rB5n7RFjhWCcbQgPGXJtksnhw4dx6dIl3H333Ubbr169ii5dukivDx06hGnTpmHHjh04e/as9C/rY8eOQafT4erVq0hKSpL2DwwMRLt27Wq9vmGMkEFERAROnz4N4PpYpWvXriExMVF6PyAgoMbzWnM/Bw4cwKlTp9C3b1+jfW6++WYcPHgQADBnzhwEBwdj9OjRFq+Vl5eHoUOHGk2K8Pf3l/7/sccew2OPPYZ9+/Zh3Lhx2LFjh8VzXb58GT4+PhbfN+eVV15Bnz598NRTT5m89+eff+LatWu44447pG2enp5ITEzEgQMHpG2Wejuqfi4ajQZBQUG45ZZbpG1hYWEAIH1W9bVz507o9XqMHDlS6imw5jNs3749br/9dixduhS9evXC4cOH8f333+OFF14wuUajRo0AoE49J0TmuFu8NHdeW/y+Wxt/arsncxwddy3F2brco7k466gYCzDOWoOJr4KUlZUBANauXYuoqCij97y9vaX/T0tLQ8uWLbFkyRJERkZCr9ejU6dODR6o7+npafRapVLV+XFVVdbczxdffIG7777bJOC1a9cOW7duxYkTJ/Dqq69i7dq1UKstj/zJy8tDenq60bbt27cjODjY6Nq//fYbOnbsWGO7g4OD6zyJ4s4770RKSgqmTp2KUaNG1elYA0uPw8x9LlW3GR6XWftZtWnTBiqVSvqHhcFNN90E4EbQBKz/mRw7diwmTJgArVaLZcuWoXXr1rjrrrtMrm147BgSEmJVW4kscbd4WdN5a/p9V6vVRo+/AeDatWs2u3ZN9+TouGuvOGvrGAswzjYEx/gqSGxsLLy9vXHs2DG0adPG6Kt58+YAro8bOnjwIJ577jn07dsXHTp0MAoWrVu3hqenp9G/rC9cuIA//vijQW276aab4OnpaTRZoLi4uMbzWnM/n3/+Oe69916TYw09vlOmTME999yDXr16WbzO5cuXcejQIeh0OmmbXq9HdnY20tPTjRLmX3/9tdYA3KVLF+zfv7/GfcyZPXs2vvzyS2zfvt1oe+vWraUxZQbXrl3Drl27EBsbW+frNFRQUBDuvvtuvPnmmygvL69xX2s+QwAYNmwY1Go1PvjgA/zvf//DmDFjzJYa+vXXXxEdHY3g4GCb3xcpi7vFy/oKCQlBQUGB9LqkpAT5+fnSa3vFH7nirrk462wxFmCcbQj2+Lqp4uJiaWKAQVBQEJ566in83//9H/R6PXr06IHi4mL8+OOP8Pf3R3p6Opo1a4agoCAsXrwYEREROHbsGKZMmSKdw9fXF2PHjsXTTz+NoKAghIaG4t///neNvaXW8PPzQ3p6Op5++mkEBgYiNDQU06dPh1qttlhL0c/Pr8b7SU1NRW5uLr744guTY2+++WYcP34cH3/8MX799dca2/bLL79ApVLhvffeQ58+fdC0aVNMmzYNFy9eNKkN/Ntvv2H8+PE1ns/Qo3DhwgU0a9aslu/MDbfccgtGjhyJN954w2h7kyZNMH78eOl716JFC8yZMweXLl2yqmRaXb355pv47LPPsHHjRov7vPXWW7jjjjuQkJCAGTNmoHPnzlCr1di1axd+//136XFgbZ+hobfH19cXw4cPx9SpU1FSUmKxN+b777/HPffcY/N7JvemhHhZX3369EFOTg7S0tKk2KfRaKT37RV/5Iq75uKso2MswDhrT0x83dR3331nNA4NuP4YY8mSJQgJCcGsWbPw119/oWnTprj11lulagZqtRorVqzAE088gU6dOqFdu3Z44403jHpEX331VZSVlSEtLQ1+fn548sknbVLMev78+XjssccwcOBA+Pv7Y/LkyTh+/HiN47JefPFFi/fz5ZdfIjEx0ey/Sm+++WYAQGZmJtq0aVNju/Ly8tC+fXtMnjwZ9913H4qLi5GSkoItW7agadOmRvta0/Nwyy234NZbb8VHH32ERx99tMZ9q3vhhRewcuVKk+2zZ8+GXq/Hgw8+iNLSUiQkJOCbb76pU2JtrbNnzxqVazKndevW2Lt3L2bOnImpU6fixIkT8Pb2RmxsLJ566ik8/vjj0r41fYZVjR07Fu+88w769++PyMhIk2teuXIFq1evxrp162xzo6QYSomX9TF16lTk5+dj4MCBCAgIwIsvvmjU4wvYJ/7IGXfNxVlHxliAcdaeVKL64B0iJ1FeXo6oqCjMmzevXv+qHjRoEHr06IHJkyebvHf+/HkEBQXh559/NplwUV1GRgYuXLiADz74oMb9Ll++jOjoaJw7d67Wtq1duxZPP/00fv311wb3/tB1CxcuxGeffYb169fL3RQih2tovHQ2jLvOyR3iLHt8yWns3bsXv//+OxITE1FcXCzNJjU3RtcaPXr0MKk/aPDzzz/Dy8sLHTp0qPU8eXl5RoXALTlw4ADat29vVdsGDBiAQ4cO4eTJk0ZjrKj+PD09sWDBArmbQeQQto6XzoZx1zm5Q5xljy85jb179+Lhhx/GwYMH4eXlha5du2L+/PlGZV9sJTs7G8uXL8fevXtr3E8IgYCAAKxYsQL9+/e3eTuIiOrDkfHS0Rh3yZ6Y+BIRERGRInCQCxEREREpAhNfIiIiIlIEJr5EREREpAhMfImIiIhIEZj4EhEREZEiMPElIiIiIkVg4ktEREREisDEl4iIiIgUgYkvERERESkCE18iIiIiUgQmvkRERESkCP8PZSeZ+MJSlrAAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\" Training (#samples,#features):\", X_train.shape)\n",
        "print(\" Testing  (#samples,#features):\", signal_test_data.shape)\n",
        "\n",
        "fig, axs = plt.subplots(1,2,figsize=(8,5))\n",
        "fig.suptitle('Kinematic distributions in bkg vs signal')\n",
        "\n",
        "axs[0].hist(X_train[:,3],bins=100,label=r'Background',histtype='step', linewidth=2, facecolor='none', edgecolor='green',fill=True,density=True)\n",
        "axs[0].hist(signal_test_data[:,3],bins=100,label=r'Signal',histtype='step', linewidth=2, facecolor='none', edgecolor='orchid',fill=True,density=True)\n",
        "axs[0].semilogy()\n",
        "axs[0].set(xlabel=u'Leading e/$\\gamma$ $p_{T}$ ( Norm. GeV)', ylabel='A.U')\n",
        "axs[0].legend(loc='best',frameon=False, ncol=1,fontsize='large')\n",
        "\n",
        "axs[1].hist(X_train[:,15],bins=100,label=r'Background',histtype='step', linewidth=2, facecolor='none', edgecolor='green',fill=True,density=True)\n",
        "axs[1].hist(signal_test_data[:,15],bins=100,label=r'Signal',histtype='step', linewidth=2, facecolor='none', edgecolor='orchid',fill=True,density=True)\n",
        "axs[1].set(xlabel=u'Leading muon $p_{T}$ (Norm. GeV)', ylabel='A.U')\n",
        "axs[1].semilogy()\n",
        "axs[1].legend(loc='best',frameon=False, ncol=1,fontsize='large')\n",
        "print(\"Example data (1,57):\",signal_test_data[3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIPnQrBrwEk8"
      },
      "source": [
        "# Defining the autoencoder\n",
        "\n",
        "Now, let's define an autoencoder to learn to reconstruct the training data after compressing it through a bottleneck, then decompressing it again.\n",
        "\n",
        "<img src=\"https://github.com/thaarres/quantumUniverse_pynqZ2/blob/master/images/ae.png?raw=1\" alt=\"The autoencoder\" width=\"800\" img align=\"center\"/>\n",
        "\n",
        "For that, we need a stack of dense layers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rBwFdeBfwEk8",
        "outputId": "dae31a04-febd-4a15-fbb4-86d9e71a39fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m57\u001b[0m)             ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense (\u001b[38;5;33mDense\u001b[0m)                   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             ‚îÇ         \u001b[38;5;34m1,856\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ batch_normalization             ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             ‚îÇ           \u001b[38;5;34m128\u001b[0m ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)            ‚îÇ                        ‚îÇ               ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)         ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             ‚îÇ           \u001b[38;5;34m528\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ batch_normalization_1           ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             ‚îÇ            \u001b[38;5;34m64\u001b[0m ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)            ‚îÇ                        ‚îÇ               ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              ‚îÇ            \u001b[38;5;34m51\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             ‚îÇ            \u001b[38;5;34m64\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ batch_normalization_2           ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             ‚îÇ            \u001b[38;5;34m64\u001b[0m ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)            ‚îÇ                        ‚îÇ               ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             ‚îÇ           \u001b[38;5;34m544\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ batch_normalization_3           ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             ‚îÇ           \u001b[38;5;34m128\u001b[0m ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)            ‚îÇ                        ‚îÇ               ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ leaky_re_lu_3 (\u001b[38;5;33mLeakyReLU\u001b[0m)       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m57\u001b[0m)             ‚îÇ         \u001b[38;5;34m1,881\u001b[0m ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                    </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape           </span>‚îÉ<span style=\"font-weight: bold\">       Param # </span>‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>)             ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,856</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ batch_normalization             ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            ‚îÇ                        ‚îÇ               ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ batch_normalization_1           ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             ‚îÇ            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            ‚îÇ                        ‚îÇ               ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              ‚îÇ            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             ‚îÇ            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ batch_normalization_2           ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             ‚îÇ            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            ‚îÇ                        ‚îÇ               ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ batch_normalization_3           ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            ‚îÇ                        ‚îÇ               ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ leaky_re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>)             ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,881</span> ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,308\u001b[0m (20.73 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,308</span> (20.73 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,116\u001b[0m (19.98 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,116</span> (19.98 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Lambda, BatchNormalization, Activation, Concatenate, Dropout, Layer\n",
        "from tensorflow.keras.layers import ReLU, LeakyReLU\n",
        "\n",
        "input_shape = 57\n",
        "latent_dim = 2\n",
        "#encoder\n",
        "inputArray = Input(shape=(input_shape,))\n",
        "#x = BatchNormalization()(inputArray) #Only use this if you're not standardizing the pT\n",
        "x = Dense(32, kernel_initializer=tf.keras.initializers.HeUniform())(inputArray)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU(alpha=0.3)(x)\n",
        "x = Dense(16, kernel_initializer=tf.keras.initializers.HeUniform())(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU(alpha=0.3)(x)\n",
        "\n",
        "#bottleneck\n",
        "encoder = Dense(latent_dim, kernel_initializer=tf.keras.initializers.HeUniform())(x)\n",
        "\n",
        "#decoder\n",
        "x = Dense(16, kernel_initializer=tf.keras.initializers.HeUniform())(encoder)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU(alpha=0.3)(x)\n",
        "x = Dense(32, kernel_initializer=tf.keras.initializers.HeUniform())(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU(alpha=0.3)(x)\n",
        "decoder = Dense(input_shape, kernel_initializer=tf.keras.initializers.HeUniform())(x)\n",
        "\n",
        "#create autoencoder\n",
        "autoencoder = Model(inputs = inputArray, outputs=decoder)\n",
        "autoencoder.summary()\n",
        "\n",
        "\n",
        "# save the encoder-only model for easy access to latent space\n",
        "encoder = Model(inputs=inputArray, outputs=encoder, name=\"encoder\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "E8qk6D0pwEk8"
      },
      "outputs": [],
      "source": [
        "autoencoder.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001), loss='mse')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GScyQXUEwEk8"
      },
      "source": [
        "# Let's train!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6zN-PBnwEk8",
        "outputId": "20813448-ee32-4904-bcb7-88674628e027",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 10ms/step - loss: 1.4190 - val_loss: 0.9958 - learning_rate: 1.0000e-05\n",
            "Epoch 2/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - loss: 0.8668 - val_loss: 0.6332 - learning_rate: 1.0000e-05\n",
            "Epoch 3/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 10ms/step - loss: 0.6027 - val_loss: 0.4866 - learning_rate: 1.0000e-05\n",
            "Epoch 4/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 9ms/step - loss: 0.4910 - val_loss: 0.4302 - learning_rate: 1.0000e-05\n",
            "Epoch 5/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - loss: 0.4372 - val_loss: 0.4042 - learning_rate: 1.0000e-05\n",
            "Epoch 6/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - loss: 0.4078 - val_loss: 0.3904 - learning_rate: 1.0000e-05\n",
            "Epoch 7/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - loss: 0.4075 - val_loss: 0.3780 - learning_rate: 1.0000e-05\n",
            "Epoch 8/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 9ms/step - loss: 0.3868 - val_loss: 0.3682 - learning_rate: 1.0000e-05\n",
            "Epoch 9/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - loss: 0.3694 - val_loss: 0.3601 - learning_rate: 1.0000e-05\n",
            "Epoch 10/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 9ms/step - loss: 0.3933 - val_loss: 0.3530 - learning_rate: 1.0000e-05\n",
            "Epoch 11/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 9ms/step - loss: 0.3568 - val_loss: 0.3471 - learning_rate: 1.0000e-05\n",
            "Epoch 12/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 10ms/step - loss: 0.3532 - val_loss: 0.3418 - learning_rate: 1.0000e-05\n",
            "Epoch 13/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 11ms/step - loss: 0.3571 - val_loss: 0.3374 - learning_rate: 1.0000e-05\n",
            "Epoch 14/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 9ms/step - loss: 0.3395 - val_loss: 0.3330 - learning_rate: 1.0000e-05\n",
            "Epoch 15/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 9ms/step - loss: 0.3493 - val_loss: 0.3293 - learning_rate: 1.0000e-05\n",
            "Epoch 16/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 12ms/step - loss: 0.3427 - val_loss: 0.3257 - learning_rate: 1.0000e-05\n",
            "Epoch 17/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 0.3273 - val_loss: 0.3228 - learning_rate: 1.0000e-05\n",
            "Epoch 18/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 11ms/step - loss: 0.3181 - val_loss: 0.3204 - learning_rate: 1.0000e-05\n",
            "Epoch 19/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - loss: 0.3258 - val_loss: 0.3176 - learning_rate: 1.0000e-05\n",
            "Epoch 20/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 0.3217 - val_loss: 0.3150 - learning_rate: 1.0000e-05\n",
            "Epoch 21/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 10ms/step - loss: 0.3242 - val_loss: 0.3127 - learning_rate: 1.0000e-05\n",
            "Epoch 22/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - loss: 0.3314 - val_loss: 0.3109 - learning_rate: 1.0000e-05\n",
            "Epoch 23/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 10ms/step - loss: 0.3032 - val_loss: 0.3095 - learning_rate: 1.0000e-05\n",
            "Epoch 24/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 9ms/step - loss: 0.3132 - val_loss: 0.3071 - learning_rate: 1.0000e-05\n",
            "Epoch 25/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 10ms/step - loss: 0.3215 - val_loss: 0.3063 - learning_rate: 1.0000e-05\n",
            "Epoch 26/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 10ms/step - loss: 0.3248 - val_loss: 0.3040 - learning_rate: 1.0000e-05\n",
            "Epoch 27/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 11ms/step - loss: 0.3042 - val_loss: 0.3016 - learning_rate: 1.0000e-05\n",
            "Epoch 28/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - loss: 0.3002 - val_loss: 0.3005 - learning_rate: 1.0000e-05\n",
            "Epoch 29/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - loss: 0.3170 - val_loss: 0.2991 - learning_rate: 1.0000e-05\n",
            "Epoch 30/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - loss: 0.3090 - val_loss: 0.2975 - learning_rate: 1.0000e-05\n",
            "Epoch 31/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - loss: 0.2877 - val_loss: 0.2963 - learning_rate: 1.0000e-05\n",
            "Epoch 32/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 11ms/step - loss: 0.2956 - val_loss: 0.2956 - learning_rate: 1.0000e-05\n",
            "Epoch 33/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 15ms/step - loss: 0.2991 - val_loss: 0.2933 - learning_rate: 1.0000e-05\n",
            "Epoch 34/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - loss: 0.2987 - val_loss: 0.2926 - learning_rate: 1.0000e-05\n",
            "Epoch 35/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 10ms/step - loss: 0.2985 - val_loss: 0.2916 - learning_rate: 1.0000e-05\n",
            "Epoch 36/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - loss: 0.2895 - val_loss: 0.2898 - learning_rate: 1.0000e-05\n",
            "Epoch 37/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 9ms/step - loss: 0.3039 - val_loss: 0.2887 - learning_rate: 1.0000e-05\n",
            "Epoch 38/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 0.2991 - val_loss: 0.2872 - learning_rate: 1.0000e-05\n",
            "Epoch 39/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 9ms/step - loss: 0.2881 - val_loss: 0.2871 - learning_rate: 1.0000e-05\n",
            "Epoch 40/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - loss: 0.2875 - val_loss: 0.2858 - learning_rate: 1.0000e-05\n",
            "Epoch 41/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 13ms/step - loss: 0.3018 - val_loss: 0.2843 - learning_rate: 1.0000e-05\n",
            "Epoch 42/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 15ms/step - loss: 0.3155 - val_loss: 0.2843 - learning_rate: 1.0000e-05\n",
            "Epoch 43/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 13ms/step - loss: 0.2802 - val_loss: 0.2824 - learning_rate: 1.0000e-05\n",
            "Epoch 44/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 10ms/step - loss: 0.2872 - val_loss: 0.2822 - learning_rate: 1.0000e-05\n",
            "Epoch 45/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - loss: 0.2719 - val_loss: 0.2817 - learning_rate: 1.0000e-05\n",
            "Epoch 46/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 10ms/step - loss: 0.2892 - val_loss: 0.2808 - learning_rate: 1.0000e-05\n",
            "Epoch 47/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - loss: 0.2944 - val_loss: 0.2796 - learning_rate: 1.0000e-05\n",
            "Epoch 48/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 11ms/step - loss: 0.2812 - val_loss: 0.2789 - learning_rate: 1.0000e-05\n",
            "Epoch 49/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 9ms/step - loss: 0.2878 - val_loss: 0.2780 - learning_rate: 1.0000e-05\n",
            "Epoch 50/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - loss: 0.2759 - val_loss: 0.2791 - learning_rate: 1.0000e-05\n",
            "Epoch 51/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - loss: 0.2918 - val_loss: 0.2768 - learning_rate: 1.0000e-05\n",
            "Epoch 52/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 9ms/step - loss: 0.2660 - val_loss: 0.2775 - learning_rate: 1.0000e-05\n",
            "Epoch 53/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 10ms/step - loss: 0.2716 - val_loss: 0.2759 - learning_rate: 1.0000e-05\n",
            "Epoch 54/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - loss: 0.2755 - val_loss: 0.2758 - learning_rate: 1.0000e-05\n",
            "Epoch 55/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - loss: 0.2736 - val_loss: 0.2741 - learning_rate: 1.0000e-05\n",
            "Epoch 56/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 9ms/step - loss: 0.2791 - val_loss: 0.2737 - learning_rate: 1.0000e-05\n",
            "Epoch 57/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 9ms/step - loss: 0.2689 - val_loss: 0.2726 - learning_rate: 1.0000e-05\n",
            "Epoch 58/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - loss: 0.2673 - val_loss: 0.2725 - learning_rate: 1.0000e-05\n",
            "Epoch 59/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - loss: 0.2718 - val_loss: 0.2724 - learning_rate: 1.0000e-05\n",
            "Epoch 60/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - loss: 0.2597 - val_loss: 0.2715 - learning_rate: 1.0000e-05\n",
            "Epoch 61/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - loss: 0.2674 - val_loss: 0.2707 - learning_rate: 1.0000e-05\n",
            "Epoch 62/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 10ms/step - loss: 0.2652 - val_loss: 0.2699 - learning_rate: 1.0000e-05\n",
            "Epoch 63/150\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - loss: 0.2776 - val_loss: 0.2688 - learning_rate: 1.0000e-05\n",
            "Epoch 64/150\n"
          ]
        }
      ],
      "source": [
        "train = True #If you have a pre-trained model you can set this to false and load the other instead\n",
        "EPOCHS = 150\n",
        "BATCH_SIZE = 1024\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TerminateOnNaN\n",
        "\n",
        "callbacks=[]\n",
        "callbacks.append(ReduceLROnPlateau(monitor='val_loss',  factor=0.1, patience=2, verbose=1, mode='auto', min_delta=0.0001, cooldown=2, min_lr=1E-6))\n",
        "callbacks.append(TerminateOnNaN())\n",
        "callbacks.append(tf.keras.callbacks.EarlyStopping(monitor='val_loss',verbose=1, patience=10, restore_best_weights=True))\n",
        "\n",
        "if train:\n",
        "    history = autoencoder.fit(X_train, X_train, epochs = EPOCHS, batch_size = BATCH_SIZE,\n",
        "                  validation_data=(X_val, X_val),\n",
        "                  callbacks=callbacks)\n",
        "    # Save the model\n",
        "    autoencoder.save('baseline_ae.h5')\n",
        "    autoencoder.save_weights('baseline_ae_weights_only.h5')\n",
        "\n",
        "else:\n",
        "    autoencoder = tf.keras.models.load_model('baseline_ae.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0OXC-lbwEk9"
      },
      "source": [
        "# Evaluating the model performance\n",
        "\n",
        "Remember that the key metric we use for anomaly detection is the mean-squared-error: If the error is high, the data is more likely to be anomalous, and if the error is low, the data is similar to the training data (which in our case is SM events). We therefore first need to run `model.predict()` in order to get the AE reconstructed output, both for our vanilla SM test data, and for our new leptoquark signal!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "af9sJyk8wEk9"
      },
      "outputs": [],
      "source": [
        "bkg_prediction = autoencoder.predict(X_test)\n",
        "signal_prediction = autoencoder.predict(signal_test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fH1__6_iwEk9"
      },
      "source": [
        "Let's see how well the network reconstructs the transverse momentum of the leptons!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSMoeq1TwEk9"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(1,2,figsize=(16,8))\n",
        "fig.suptitle('Real data versus reconsructed data')\n",
        "axs[0].hist(X_test[:,3],bins=100,label=r'Real data',histtype='step', linewidth=2, facecolor='none', edgecolor='green',fill=True,density=True)\n",
        "axs[0].hist(bkg_prediction[:,3],bins=100,label=r'Predicted',histtype='step', linewidth=2, facecolor='none', edgecolor='orchid',fill=True,density=True)\n",
        "axs[0].semilogy()\n",
        "axs[0].set(xlabel=u'Leading e/$\\gamma$ $p_{T}$ ( Norm. GeV)', ylabel='A.U')\n",
        "axs[0].legend(loc='best',frameon=False, ncol=1,fontsize='large')\n",
        "\n",
        "axs[1].hist(X_test[:,15],bins=100,label=r'Real data',histtype='step', linewidth=2, facecolor='none', edgecolor='green',fill=True,density=True)\n",
        "axs[1].hist(bkg_prediction[:,15],bins=100,label=r'Predicted',histtype='step', linewidth=2, facecolor='none', edgecolor='orchid',fill=True,density=True)\n",
        "axs[1].set(xlabel=u'Leading muon $p_{T}$ (Norm. GeV)', ylabel='A.U')\n",
        "axs[1].semilogy()\n",
        "axs[1].legend(loc='best',frameon=False, ncol=1,fontsize='large')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI5tcXq2wEk9"
      },
      "source": [
        "The reconstructed $p_T$ has an unphysical tail below zero. For a real usecase, we would force the output to be positive for that column, as well as treat the zero-padded cases differently in the loss.\n",
        "To keep it short, we won't do that now, but you can read more about it [here](https://arxiv.org/abs/2108.03986)\n",
        "\n",
        "We then need to compute the mean-square-error, which will be our final discriminating variable. This you would need to write custom if applying the changes we mention above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvI8Zy5qwEk9"
      },
      "outputs": [],
      "source": [
        "def mse_loss(true, prediction):\n",
        "    loss = tf.reduce_mean(tf.math.square(true - prediction),axis=-1)\n",
        "    return loss\n",
        "\n",
        "# compute loss value of input data versus AE reconstructed data\n",
        "mse_sm = mse_loss(X_test, bkg_prediction.astype(np.float32)).numpy()\n",
        "mse_bsm = mse_loss(signal_test_data,signal_prediction.astype(np.float32)).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTYjtQN0wEk9"
      },
      "source": [
        "Now, let's look at our discriminant!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEs0PLwowEk-"
      },
      "outputs": [],
      "source": [
        "bin_size=100\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "n, bins, patches =plt.hist(mse_bsm, bins=bin_size, label=\"Leptoquark\", density = True, histtype='step', fill=False, edgecolor='orchid', linewidth=1.5,range=[0,200])\n",
        "n_, bins_, patches_ =plt.hist(mse_sm, bins=bin_size, label=\"SM Background\", density = True, histtype='step', fill=False, edgecolor='green', linewidth=1.5,range=[0,200])\n",
        "plt.yscale('log')\n",
        "plt.xlabel(\"Mean-squared-error\")\n",
        "plt.ylabel(\"Probability (a.u.)\")\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8XFNW4WwEk-"
      },
      "source": [
        "There seems to be some discrimination power if we cut at very high values of the MSE! Let's look at a ROC curve to make it easier to vizualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uU2mvS-5wEk-"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "target_background = np.zeros(mse_sm.shape[0])\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "trueVal = np.concatenate((np.ones(mse_bsm.shape[0]), target_background)) # anomaly=1, bkg=0\n",
        "predVal_loss = np.concatenate((mse_bsm, mse_sm))\n",
        "\n",
        "fpr_loss, tpr_loss, threshold_loss = roc_curve(trueVal, predVal_loss)\n",
        "\n",
        "auc_loss = auc(fpr_loss, tpr_loss)\n",
        "\n",
        "plt.plot(fpr_loss, tpr_loss, \"-\", label='Leptoquark (auc = %.1f%%)'%(auc_loss*100.), linewidth=1.5, color = \"orchid\")\n",
        "\n",
        "plt.semilogx()\n",
        "plt.semilogy()\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.legend(loc='center right')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.plot(np.linspace(0, 1),np.linspace(0, 1), '--', color='0.75')\n",
        "plt.axvline(0.00001, color='green', linestyle='dashed', linewidth=2) # threshold value for measuring anomaly detection efficiency\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dgkhw6mwEk-"
      },
      "source": [
        "Pretty good! So at a false positive rate of 10E-5, the signal efficiency is almost three orders of magnitude higher! This can obviously be further improved, but I leave that up to you :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRG-y_HJwEk-"
      },
      "source": [
        "## Model compression\n",
        "<img src=\"https://github.com/thaarres/quantumUniverse_pynqZ2/blob/master/images/nmi_qkeras_hls4ml.jpeg?raw=1\" alt=\"hls4ml and qkeras\" width=\"200\" img align=\"left\"/>\n",
        "\n",
        "Now, there is absolutely no way anyone would let you deploy this model on an FPGA in the trigger. It will use far too many resources! Luckily, as we discussed in the lecture, there are some cheap tricks you can perform to compress the model. These are pruning and quantization-aware-training and both are very easily implemented. Let's have a look.\n",
        "\n",
        "To quantize the model during training, such that the network will get the opportunity to adapt to the narrower bitwidth we use the library [QKeras](https://www.nature.com/articles/s42256-021-00356-5.epdf?sharing_token=A6MQVmmncHNyCtDUXzrqtNRgN0jAjWel9jnR3ZoTv0N3uekY-CrHD1aJ9BTeJNRfQ1EhZ9jJIhgZjfrQxrmxMLMZ4eGzSeru7-ASFE-Xt3NVE6yorlffwUN0muAm1auU2I6-5ug4bOLCRYvA0mp-iT-OdPsrBYeH0IHRYx0t3wc%3D), developed in a joint effort between CERN and Google."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShFIoR_-wEk-"
      },
      "outputs": [],
      "source": [
        "from qkeras import QDense, QActivation\n",
        "\n",
        "#encoder\n",
        "inputArray = Input(shape=(input_shape))\n",
        "# x = BatchNormalization()(inputArray)\n",
        "x = QDense(32, kernel_initializer=tf.keras.initializers.HeUniform(),\n",
        "               kernel_quantizer='quantized_bits(8,3,1, alpha=1.0)',\n",
        "               bias_quantizer='quantized_bits(8,3,1, alpha=1.0)')(inputArray)\n",
        "x = BatchNormalization()(x)\n",
        "x = QActivation('quantized_relu(bits=8)')(x)\n",
        "x = QDense(16, kernel_initializer=tf.keras.initializers.HeUniform(),\n",
        "               kernel_quantizer='quantized_bits(8,3,1, alpha=1.0)',\n",
        "               bias_quantizer='quantized_bits(8,3,1, alpha=1.0)')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = QActivation('quantized_relu(bits=8)')(x)\n",
        "encoder = QDense(latent_dim, kernel_initializer=tf.keras.initializers.HeUniform(),\n",
        "               kernel_quantizer='quantized_bits(16,6,1, alpha=1.0)',\n",
        "               bias_quantizer='quantized_bits(16,6,1, alpha=1.0)', name='bottleneck')(x)\n",
        "\n",
        "#decoder\n",
        "x = QDense(16, kernel_initializer=tf.keras.initializers.HeUniform(),\n",
        "               kernel_quantizer='quantized_bits(8,3,1, alpha=1.0)',\n",
        "               bias_quantizer='quantized_bits(8,3,1, alpha=1.0)')(encoder)\n",
        "x = BatchNormalization()(x)\n",
        "x = QActivation('quantized_relu(bits=8)')(x)\n",
        "x = QDense(32, kernel_initializer=tf.keras.initializers.HeUniform(),\n",
        "               kernel_quantizer='quantized_bits(8,3,1, alpha=1.0)',\n",
        "               bias_quantizer='quantized_bits(8,3,1, alpha=1.0)')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = QActivation('quantized_relu(bits=8)')(x)\n",
        "decoder = QDense(input_shape, kernel_initializer=tf.keras.initializers.HeUniform(),\n",
        "               kernel_quantizer='quantized_bits(16,6,1, alpha=1.0)',\n",
        "               bias_quantizer='quantized_bits(16,6,1, alpha=1.0)')(x)\n",
        "\n",
        "#create autoencoder\n",
        "q_autoencoder = Model(inputs = inputArray, outputs=decoder)\n",
        "q_autoencoder.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTTmPGrswEk-"
      },
      "source": [
        "Easy as that! Let's add some pruning on top, 50% sparsity (removing 50% of the weights). Let's make sure to skip our latent dimension!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sxj04wUZwEk-"
      },
      "outputs": [],
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "from tensorflow_model_optimization.python.core.sparsity.keras import prune, pruning_callbacks, pruning_schedule\n",
        "from tensorflow_model_optimization.sparsity.keras import strip_pruning\n",
        "\n",
        "def pruneFunction(layer):\n",
        "    pruning_params = {'pruning_schedule': pruning_schedule.PolynomialDecay(initial_sparsity=0.05,final_sparsity=0.50, begin_step=0, end_step=100, frequency=100)}\n",
        "    if isinstance(layer, tf.keras.layers.Dense) and layer.name!='bottleneck':\n",
        "      return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params)\n",
        "    return layer\n",
        "\n",
        "q_autoencoder.load_weights('baseline_ae_weights_only.h5')\n",
        "qp_autoencoder = tf.keras.models.clone_model( q_autoencoder, clone_function=pruneFunction)\n",
        "qp_autoencoder.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001), loss='mse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crrPM6d2wEk_"
      },
      "outputs": [],
      "source": [
        "train = False\n",
        "EPOCHS = 150\n",
        "BATCH_SIZE = 1024\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TerminateOnNaN\n",
        "\n",
        "callbacks=[]\n",
        "callbacks.append(ReduceLROnPlateau(monitor='val_loss',  factor=0.1, patience=2, verbose=1, mode='auto', min_delta=0.0001, cooldown=2, min_lr=1E-6))\n",
        "callbacks.append(TerminateOnNaN())\n",
        "callbacks.append(tf.keras.callbacks.EarlyStopping(monitor='val_loss',verbose=1, patience=10, restore_best_weights=False))\n",
        "callbacks.append(pruning_callbacks.UpdatePruningStep())\n",
        "if train:\n",
        "\n",
        "    history = qp_autoencoder.fit(X_train, X_train, epochs = EPOCHS, batch_size = BATCH_SIZE,\n",
        "                  validation_data=(X_val, X_val),\n",
        "                  callbacks=callbacks)\n",
        "    # Save the model\n",
        "    qp_autoencoder = strip_pruning(qp_autoencoder)\n",
        "    qp_autoencoder.save('qkeras_ae.h5')\n",
        "\n",
        "else:\n",
        "    from qkeras.utils import _add_supported_quantized_objects\n",
        "    co = {}; _add_supported_quantized_objects(co)\n",
        "\n",
        "    qp_autoencoder = tf.keras.models.load_model('qkeras_ae.h5',custom_objects=co)\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGWQ3ffjwEk_"
      },
      "source": [
        "Let's quickly check that the pruning worked and 30% of the weights are indeed 0!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Df-bSRMlwEk_"
      },
      "outputs": [],
      "source": [
        "def doWeights(model):\n",
        "\n",
        "    allWeightsByLayer = {}\n",
        "    for layer in model.layers:\n",
        "        if (layer._name).find(\"batch\")!=-1 or len(layer.get_weights())<1:\n",
        "            continue\n",
        "        weights=layer.weights[0].numpy().flatten()\n",
        "        allWeightsByLayer[layer._name] = weights\n",
        "        print('Layer {}: % of zeros = {}'.format(layer._name,np.sum(weights==0)/np.size(weights)))\n",
        "\n",
        "    labelsW = []\n",
        "    histosW = []\n",
        "\n",
        "    for key in reversed(sorted(allWeightsByLayer.keys())):\n",
        "        labelsW.append(key)\n",
        "        histosW.append(allWeightsByLayer[key])\n",
        "\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    bins = np.linspace(-1.5, 1.5, 50)\n",
        "    plt.hist(histosW,bins,histtype='stepfilled',stacked=True,label=labelsW, edgecolor='black')\n",
        "    plt.legend(frameon=False,loc='upper left')\n",
        "    plt.ylabel('Number of Weights')\n",
        "    plt.xlabel('Weights')\n",
        "    plt.figtext(0.2, 0.38,model._name, wrap=True, horizontalalignment='left',verticalalignment='center')\n",
        "\n",
        "doWeights(autoencoder)\n",
        "doWeights(qp_autoencoder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31tQCaA6wEk_"
      },
      "source": [
        "Indeed, a huge spike at zero for the pruned model! Let's compare the performance to the floating point precision, unpruned model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3h3MDOMSwEk_"
      },
      "outputs": [],
      "source": [
        "bkg_prediction = qp_autoencoder.predict(X_test)\n",
        "signal_prediction = qp_autoencoder.predict(signal_test_data)\n",
        "\n",
        "# compute loss value of input data versus AE reconstructed data\n",
        "q_mse_sm = mse_loss(X_test, bkg_prediction.astype(np.float32)).numpy()\n",
        "q_mse_bsm = mse_loss(signal_test_data,signal_prediction.astype(np.float32)).numpy()\n",
        "\n",
        "target_background = np.zeros(q_mse_sm.shape[0])\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "trueVal = np.concatenate((np.ones(q_mse_bsm.shape[0]), target_background)) # anomaly=1, bkg=0\n",
        "predVal_loss = np.concatenate((q_mse_bsm, q_mse_sm))\n",
        "\n",
        "q_fpr_loss, q_tpr_loss, q_threshold_loss = roc_curve(trueVal, predVal_loss)\n",
        "\n",
        "q_auc_loss = auc(q_fpr_loss, q_tpr_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUY_bOPpwEk_"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,8))\n",
        "\n",
        "plt.plot(fpr_loss, tpr_loss, \"-\", label='Baseline (auc = %.1f%%)'%(auc_loss*100.), linewidth=1.5, color = \"orchid\")\n",
        "plt.plot(q_fpr_loss, q_tpr_loss, \"-\", label='Quantized+Pruned (auc = %.1f%%)'%(q_auc_loss*100.), linewidth=1.5, color = \"green\")\n",
        "\n",
        "plt.semilogx()\n",
        "plt.semilogy()\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.legend(loc='center right')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.ylim(0.001,1)\n",
        "plt.plot(np.linspace(0, 1),np.linspace(0, 1), '--', color='0.75')\n",
        "plt.axvline(0.00001, color='orange', linestyle='dashed', linewidth=2) # threshold value for measuring anomaly detection efficiency\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03CHQhOkwEk_"
      },
      "source": [
        "Take a moment to appreciate what an absolutely fantastic result this is! We can reduce the numerical precision of the model from floating point 32 representation to 8-bit fixed point precision, remove 50% of the weights *and still get the same performance*!! This is a crucial, and absolutely neccessary, part of making deep neural networks in particle detector data aquisition systems a reality (also, note that AUC is not a good metric for trigger applications, where you typically operate at very low false positive rates of 10E-5)."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "guWEk_Lmwc3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercises\n",
        "\n",
        "- Perform a PCA on the training images using sklearn.decomposition.PCA with 2 components.\n",
        "\n",
        "- Plot the PCA ROC curve. Report the AUC.\n",
        "\n",
        "- Plot the 2D latent space for signal and background\n",
        "\n",
        "- Turn the AE into a VAE. Hints:"
      ],
      "metadata": {
        "id": "InNeC2pfzDFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Step 2: Apply PCA\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Step 3: Plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X_pca[:, 0], X_pca[:, 1], alpha=0.6, c='blue', edgecolor='k')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PvDSV8SYzFLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode test data to latent space\n",
        "latent_representations = encoder.predict(X_test)\n",
        "latent_representations_b = encoder.predict(X_test)\n",
        "latent_representations_s = encoder.predict(signal_test_data)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(latent_representations_b[:, 0], latent_representations_b[:, 1], alpha=0.6, c='blue', edgecolor='k')\n",
        "plt.scatter(latent_representations_s[:, 0], latent_representations_s[:, 1], alpha=0.6, c='red', edgecolor='k')\n",
        "plt.xlabel(\"Latent Dimension 1\")\n",
        "plt.ylabel(\"Latent Dimension 2\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OVPXSmB41Vjq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}