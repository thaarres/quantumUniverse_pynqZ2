{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making firmware with hls4ml\n",
    "\n",
    "This is the fun part! Now we'll convert our Keras model into highly parallel FPGA firmware with hls4ml, using only a few lines of code.\n",
    "\n",
    "<img src=\"images/hls4ml_conifer.png\" alt=\"hls4ml\" width=\"1000\" img align=\"center\"/>\n",
    "\n",
    "Let's make bitfiles both of the large and the compressed model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: batch_normalization, layer type: BatchNormalization\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense\n",
      "Layer name: batch_normalization_1, layer type: BatchNormalization\n",
      "Layer name: leaky_re_lu, layer type: LeakyReLU\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: batch_normalization_2, layer type: BatchNormalization\n",
      "Layer name: leaky_re_lu_1, layer type: LeakyReLU\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: batch_normalization_3, layer type: BatchNormalization\n",
      "Layer name: leaky_re_lu_2, layer type: LeakyReLU\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_4\n",
      "Layer name: batch_normalization_4, layer type: BatchNormalization\n",
      "Layer name: leaky_re_lu_3, layer type: LeakyReLU\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 57]], output shape: [None, 57]\n",
      "Layer name: batch_normalization, layer type: BatchNormalization, input shapes: [[None, 57]], output shape: [None, 57]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 57]], output shape: [None, 32]\n",
      "Layer name: batch_normalization_1, layer type: BatchNormalization, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: leaky_re_lu, layer type: LeakyReLU, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: batch_normalization_2, layer type: BatchNormalization, input shapes: [[None, 16]], output shape: [None, 16]\n",
      "Layer name: leaky_re_lu_1, layer type: LeakyReLU, input shapes: [[None, 16]], output shape: [None, 16]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 3]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 3]], output shape: [None, 16]\n",
      "Layer name: batch_normalization_3, layer type: BatchNormalization, input shapes: [[None, 16]], output shape: [None, 16]\n",
      "Layer name: leaky_re_lu_2, layer type: LeakyReLU, input shapes: [[None, 16]], output shape: [None, 16]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 32]\n",
      "Layer name: batch_normalization_4, layer type: BatchNormalization, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: leaky_re_lu_3, layer type: LeakyReLU, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 57]\n",
      "Creating HLS model\n",
      "WARNING: Invalid ReuseFactor=64 with \"Resource\" strategy in layer \"dense\". Using ReuseFactor=57 instead. Valid ReuseFactor(s): 3,19,57,114,228,456,912,1824.\n",
      "WARNING: Invalid ReuseFactor=64 with \"Resource\" strategy in layer \"dense_2\". Using ReuseFactor=48 instead. Valid ReuseFactor(s): 2,4,8,16,48.\n",
      "WARNING: Invalid ReuseFactor=64 with \"Resource\" strategy in layer \"dense_3\". Using ReuseFactor=48 instead. Valid ReuseFactor(s): 3,6,12,24,48.\n",
      "WARNING: Invalid ReuseFactor=64 with \"Resource\" strategy in layer \"dense_5\". Using ReuseFactor=32 instead. Valid ReuseFactor(s): 2,4,8,16,32,96,608,1824.\n",
      "WARNING: You set a XilinxPart that does not correspond to the Board you specified. The correct XilinxPart is now set.\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sh: vivado_hls: command not found\n",
      "sh: vivado: command not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project myproject_prj does not exist. Rerun \"hls4ml build -p baseline_ae_pynq\".\n",
      "File baseline_ae_pynq/myproject_vivado_accelerator/project_1.runs/impl_1/design_1_wrapper.bit not found, waiting 60s before retry\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/lx/xk6v8st56q5cw8gw5s3xxv6c0000gn/T/ipykernel_39377/463122855.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mhls_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msynth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mhls4ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemplates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVivadoAcceleratorBackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_bitfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhls_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpackage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhls_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignal_test_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hls4ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Then the compressed model:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/TUTORIALS/quantumUniverse_pynqZ2/util.py\u001b[0m in \u001b[0;36mpackage\u001b[0;34m(hls_model, X, y, name, sleep_before_retry)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{odir}/{name}_vivado_accelerator/project_1.runs/impl_1/design_1_wrapper.bit'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{odir}/package/{name}.bit'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mcopy_wait_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{odir}/{name}_vivado_accelerator/project_1.srcs/sources_1/bd/design_1/hw_handoff/design_1.hwh'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/TUTORIALS/quantumUniverse_pynqZ2/util.py\u001b[0m in \u001b[0;36mcopy_wait_retry\u001b[0;34m(src, dst, sleep)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'File {src} not found, waiting {sleep}s before retry'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import hls4ml\n",
    "import util\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from qkeras.utils import _add_supported_quantized_objects\n",
    "co = {}; _add_supported_quantized_objects(co)\n",
    "\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.layers = ['Activation']\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.rounding_mode = 'AP_RND'\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.saturation_mode = 'AP_SAT'\n",
    "\n",
    "with h5py.File('Ato4l_dataset.h5', 'r') as file:\n",
    "    signal_test_data = np.array(file['Data'])\n",
    "\n",
    "# First the baseline:\n",
    "autoencoder = tf.keras.models.load_model('baseline_ae.h5')\n",
    "\n",
    "config = hls4ml.utils.config_from_keras_model(autoencoder, granularity='name')\n",
    "config['Model']['Strategy'] = 'Resource'\n",
    "\n",
    "for layer in config['LayerName'].keys():\n",
    "    config['LayerName'][layer]['ReuseFactor'] = 64\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(autoencoder,\n",
    "                                                         hls_config=config,\n",
    "                                                         backend='VivadoAccelerator',\n",
    "                                                         output_dir='baseline_ae_pynq',\n",
    "                                                         board='pynq-z2')\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.layers = []                                                     \n",
    "hls_model.compile()\n",
    "\n",
    "y_hls4ml = hls_model.predict(np.ascontiguousarray(signal_test_data))\n",
    "hls_model.build(csim=False, synth=True, export=True)\n",
    "hls4ml.templates.VivadoAcceleratorBackend.make_bitfile(hls_model)\n",
    "util.package(hls_model, signal_test_data, y_hls4ml)\n",
    "\n",
    "# Then the compressed model:\n",
    "q_autoencoder = tf.keras.models.load_model('compressed_ae.h5')\n",
    "\n",
    "config = hls4ml.utils.config_from_keras_model(q_autoencoder, granularity='name')\n",
    "config['Model']['Strategy'] = 'Resource'\n",
    "for layer in config['LayerName'].keys():\n",
    "    config['LayerName'][layer]['ReuseFactor'] = 64\n",
    "q_hls_model = hls4ml.converters.convert_from_keras_model(q_autoencoder,\n",
    "                                                         hls_config=config,\n",
    "                                                         backend='VivadoAccelerator',\n",
    "                                                         output_dir='\n",
    "                                                         ',\n",
    "                                                         board='pynq-z2')\n",
    "q_hls_model.model.optimizer.OutputRoundingSaturationMode.layers = []                                                     \n",
    "q_hls_model.compile()\n",
    "\n",
    "y_q_hls4ml = q_hls_model.predict(np.ascontiguousarray(signal_test_data))\n",
    "hls_model.build(csim=False, synth=True, export=True)\n",
    "hls4ml.templates.VivadoAcceleratorBackend.make_bitfile(q_hls_model)\n",
    "util.package(q_hls_model, signal_test_data, y_q_hls4ml)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "files = os.listdir('.')\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
